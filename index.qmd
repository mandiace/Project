---
title: "Final Project"
author: "Mandi Acevedo, Kevin Velasco, Bela Walkin"
format: html
editor: visual
---

```{r, warning=FALSE, message=FALSE}
library(dplyr)
library(httr)
library(jsonlite)
library(modelr)
library(parsnip)
library(recipes)
library(sf)
library(stringr)
library(tidycensus)
library(tidymodels)
library(tidyr)
library(tidyverse)

```

# Data cleaning & structuring

## 2020/2016 data

### Download 2020/2016 election results data

```{r, warning=FALSE, message=FALSE}
elections2016  <- read_csv("data/2016_US_County_Level_Presidential_Results.csv")

elections2020  <- read_csv("data/2020_US_County_Level_Presidential_Results.csv")

```

### Merge 2020/2016 data into single file

```{r}
elections2020 <- elections2020 |>
  mutate(county_fips = as.character(str_remove(county_fips, "^0"))) 

elections2016 <- elections2016 |>
  mutate(county_fips = as.character(combined_fips)) |>
  select(-combined_fips, -diff) |> 
  mutate(diff = (votes_gop - votes_dem))
  

elections2020_2016 <- left_join(elections2020,
                                elections2016,
                                by = "county_fips")

colnames(elections2020_2016) <- gsub("\\.x$", "_current", colnames(elections2020_2016))
colnames(elections2020_2016) <- gsub("\\.y$", "_previous", colnames(elections2020_2016))

elections2020_2016 <- elections2020_2016 |>
  mutate(county_name = county_name_current) |>
  select(-county_name_previous, -county_name_current)

```

### Download county size data

```{r, warning=FALSE, message=FALSE}

county_size <- read_csv("data/LND01.csv") |> 
  select(STCOU,
         LND010190D) |> 
  rename(geoid = STCOU,
         land_area = LND010190D) |> 
  mutate(geoid = sub("^0+", "", geoid))

```

### Download 2019 predictor data via API

```{r, warning=FALSE, message=FALSE}

# download county size data

county_size <- read_csv("data/LND01.csv") |> 
  select(STCOU,
         LND010190D) |> 
  rename(geoid = STCOU,
         land_area = LND010190D) |> 
  mutate(geoid = sub("^0+", "", geoid))

# manually inputting data on CT county-equivalents

ct_county_eq_size <- data.frame(
  geoid = c(9110, 9120, 9130, 9140, 9150, 9160, 9170, 9180, 9190),
  land_area = c(1027.3, 140.2, 424.1, 412.8, 553.9, 786.6, 367.2, 598.1, 532.1)
) |> 
  mutate(geoid = as.character(geoid))

county_size <- county_size |> 
  bind_rows(ct_county_eq_size)

# download county demographic data

predictors2019 <- get_acs(dataset = "acs5",
                    year = 2019,
                    geography = "county",
                    variables = c(
                      # educational attainment
                      count18to24 = "S1501_C01_001",
                      count24to34 = "S1501_C01_016",
                      count35to44 = "S1501_C01_019",
                      count45to64 = "S1501_C01_022",
                      count65over = "S1501_C01_025",
                      countlessthanhs = "S1501_C01_002",
                      counthsgrad = "S1501_C01_003",
                      countsomecollegeassociates = "S1501_C01_004",
                      countbachhigher = "S1501_C01_005",
                      # total population
                      totalpopulation = "B01003_001",
                      # demographic information
                      maleratioper100females = "DP05_0004",
                      medianage = "DP05_0018",
                      countwhite = "DP05_0037",
                      countblack = "DP05_0038",
                      counthispanic = "DP05_0071",
                      # income
                      medianincome = "S1901_C01_012",
                      medianhhincome = "S1901_C02_012",
                      countbelowpoverty = "S1701_C02_001",
                      medianhousingcosts = "S2503_C01_024",
                      gini = "B19083_001",
                      # employment
                      countlaborforce16plus = "DP03_0002",
                      countunemployedinlaborforce16plus = "DP03_0005",
                      # foreign born
                      countforeignborncitizen = "B05002_013",
                      countforeignbornundocumented = "B05002_021")) |> 
  select(!moe) |> 
  pivot_wider(names_from = variable,
              values_from = estimate)
                      
predictors2019 <- predictors2019 |> 
  mutate(count18over = count18to24 + count24to34 + count35to44 + count45to64 + count65over,
         prop_less_than_hs = countlessthanhs / count18to24,
         prop_hs_grad = counthsgrad / count18to24,
         prop_some_college_associates = countsomecollegeassociates / count18to24,
         prop_bachelors_higher = countbachhigher / count18to24,
         prop_18_to_24 = count18to24 / totalpopulation,
         prop_65_years_older = count65over / totalpopulation,
         prop_white = countwhite / totalpopulation,
         prop_black = countblack / totalpopulation,
         prop_hispanic = counthispanic / totalpopulation,
         poverty_rate = countbelowpoverty / totalpopulation,
         unemployment_rate = countunemployedinlaborforce16plus / countlaborforce16plus,
         prop_foreign_born_citizen = countforeignborncitizen / totalpopulation,
         prop_undocumented = countforeignbornundocumented / totalpopulation,
         year = 2019) |> 
  rename(male_ratio_per_100_females = maleratioper100females,
         median_age = medianage,
         median_income = medianincome, 
         median_housing_costs = medianhousingcosts,
         total_population = totalpopulation,
         geoid = GEOID,
         name = NAME) |> 
  select(geoid,
         name,
         total_population,
         prop_less_than_hs,
         prop_hs_grad,
         prop_some_college_associates,
         prop_bachelors_higher,
         prop_18_to_24,
         prop_65_years_older,
         prop_white,
         prop_black,
         prop_hispanic,
         poverty_rate,
         unemployment_rate,
         male_ratio_per_100_females,
         median_age,
         median_income,
         gini,
         median_housing_costs,
         prop_foreign_born_citizen,
         prop_undocumented) |> 
  mutate(geoid = sub("^0+", "", geoid))

# merging county size predictors and calculating population density

predictors2019 <- left_join(x = predictors2019,
                      y = county_size,
                      by = "geoid") |> 
  mutate(land_area = as.numeric(land_area),
         population_density = total_population / land_area)

```

### Merge elections & predictor dataframes

```{r}

predictors2019 <- predictors2019 |>
  mutate(county_fips = geoid) |>
  select(-name, -geoid)
  
  
finaldata2020 <- left_join(x = elections2020_2016,
                      y = predictors2019,
                      by = "county_fips") |>
  na.omit()

```

## 2024/2020 data

### Download 2024 election results data

```{r, warning=FALSE, message=FALSE}
elections2024  <- read_csv("data/2024_US_County_Level_Presidential_Results.csv")

```

### Merge 2024/2020 data into single file

```{r, warning=FALSE, message=FALSE}
# fixing dc issue so that data for all wards is in one row

dc_data <- elections2024 |>
  filter(state_name == "District of Columbia") |>
  mutate(
    weighted_percent_votes_gop = per_gop * total_votes,
    weighted_percent_votes_dem = per_dem * total_votes,
    weighted_percent_points_diff = per_point_diff * total_votes
  ) |> 
  summarize(
    county_fips = 11001,
    votes_gop = sum(votes_gop),
    votes_dem = sum(votes_dem),
    total_votes = sum(total_votes),
    diff = sum(diff),
    per_gop = sum(weighted_percent_votes_gop) / sum(total_votes),
    per_dem = sum(weighted_percent_votes_dem) / sum(total_votes),
    per_point_diff = sum(weighted_percent_points_diff) / sum(total_votes),
    state_name = "District of Columbia",
    county_name = "District of Columbia"
  ) |> 
  mutate(county_fips = as.character(county_fips))

elections2024 <- elections2024 |> 
  filter(!county_fips %in% c(11001, 11002, 11003, 11004, 11005, 11006, 11007, 11008)) |> 
  bind_rows(dc_data)

# rest of merge

elections2024 <- elections2024 |>
  mutate(county_fips = as.character(str_remove(county_fips, "^0"))) 

elections2024_2020 <- left_join(elections2024,
                                elections2020,
                                by = "county_fips")

colnames(elections2024_2020) <- gsub("\\.x$", "_current", colnames(elections2024_2020))
colnames(elections2024_2020) <- gsub("\\.y$", "_previous", colnames(elections2024_2020))

elections2024_2020 <- elections2024_2020 |>
  mutate(county_name = county_name_current) |>
  select(-county_name_previous, -county_name_current)

elections2024_2020 <- elections2024_2020 |>
  mutate(state_name = state_name_current) |>
  select(-state_name_previous, -state_name_current)
```

### Download 2022 predictor data via API

```{r, warning=FALSE, message=FALSE}

# download county demographic data

predictors2022 <- get_acs(dataset = "acs5",
                    year = 2022,
                    geography = "county",
                    variables = c(
                      # educational attainment
                      count18to24 = "S1501_C01_001",
                      count24to34 = "S1501_C01_016",
                      count35to44 = "S1501_C01_019",
                      count45to64 = "S1501_C01_022",
                      count65over = "S1501_C01_025",
                      countlessthanhs = "S1501_C01_002",
                      counthsgrad = "S1501_C01_003",
                      countsomecollegeassociates = "S1501_C01_004",
                      countbachhigher = "S1501_C01_005",
                      # total population
                      totalpopulation = "B01003_001",
                      # demographic information
                      maleratioper100females = "DP05_0004",
                      medianage = "DP05_0018",
                      countwhite = "DP05_0037",
                      countblack = "DP05_0038",
                      counthispanic = "DP05_0071",
                      # income
                      medianincome = "S1901_C01_012",
                      medianhhincome = "S1901_C02_012",
                      countbelowpoverty = "S1701_C02_001",
                      medianhousingcosts = "S2503_C01_024",
                      gini = "B19083_001",
                      # employment
                      countlaborforce16plus = "DP03_0002",
                      countunemployedinlaborforce16plus = "DP03_0005",
                      # foreign born
                      countforeignborncitizen = "B05002_013",
                      countforeignbornundocumented = "B05002_021")) |> 
  select(!moe) |> 
  pivot_wider(names_from = variable,
              values_from = estimate)

predictors2022 <- predictors2022 |> 
  mutate(count18over = count18to24 + count24to34 + count35to44 + count45to64 + count65over,
         prop_less_than_hs = countlessthanhs / count18to24,
         prop_hs_grad = counthsgrad / count18to24,
         prop_some_college_associates = countsomecollegeassociates / count18to24,
         prop_bachelors_higher = countbachhigher / count18to24,
         prop_18_to_24 = count18to24 / totalpopulation,
         prop_65_years_older = count65over / totalpopulation,
         prop_white = countwhite / totalpopulation,
         prop_black = countblack / totalpopulation,
         prop_hispanic = counthispanic / totalpopulation,
         poverty_rate = countbelowpoverty / totalpopulation,
         unemployment_rate = countunemployedinlaborforce16plus / countlaborforce16plus,
         prop_foreign_born_citizen = countforeignborncitizen / totalpopulation,
         prop_undocumented = countforeignbornundocumented / totalpopulation,
         year = 2022) |> 
  rename(male_ratio_per_100_females = maleratioper100females,
         median_age = medianage,
         median_income = medianincome, 
         median_housing_costs = medianhousingcosts,
         total_population = totalpopulation,
         geoid = GEOID,
         name = NAME) |> 
  select(geoid,
         name,
         total_population,
         prop_less_than_hs,
         prop_hs_grad,
         prop_some_college_associates,
         prop_bachelors_higher,
         prop_18_to_24,
         prop_65_years_older,
         prop_white,
         prop_black,
         prop_hispanic,
         poverty_rate,
         unemployment_rate,
         male_ratio_per_100_females,
         median_age,
         median_income,
         gini,
         median_housing_costs,
         prop_foreign_born_citizen,
         prop_undocumented) |> 
  mutate(geoid = sub("^0+", "", geoid))

# merging county size predictors and calculating population density

predictors2022 <- left_join(x = predictors2022,
                      y = county_size,
                      by = "geoid") |> 
  mutate(land_area = as.numeric(land_area),
         population_density = total_population / land_area)

```
Why did we choose these predictors? 

According to a study conducted by Kulachi et al. (2023), voting behavior is very dynamic. People's voting patterns depend on a culmination of numerous factors. Some factors shown to impact voting behavior that are included in this analysis are economic, gender, ethnicity and race, and age variables. Thus, we pulled predictors within these groupings. Other factors that have been shown to influence voting behaviors, like health care experiences, media influences, are difficult to estimate at an individual level. Thus, these are much more difficult to estimate at a county level. Due to the complexities in estimating these variables and limited data access, we do not include these variables in our analysis. 

### Merge elections & predictor dataframes

```{r, warning=FALSE, message=FALSE}

predictors2022 <- predictors2022 |>
  mutate(county_fips = geoid) |>
  select(-name, -geoid)
  
  
finaldata2024 <- left_join(x = elections2024_2020,
                      y = predictors2022,
                      by = "county_fips") 

```

# Set up testing environment using 2020 data

## Initial split

```{r}
set.seed(12071999)

modeling_sample <- initial_split(finaldata2020)

train <- training(modeling_sample)
test <- testing(modeling_sample)

```

## Exploratory analysis

```{r, warning=FALSE, message=FALSE}

library(ggplot2)
library(scales)

theme_set(theme_minimal())

elections2016 |>
  mutate(winner = ifelse(diff < 0, "dem", "rep")) |> 
  ggplot(aes(x = diff, fill = winner)) +
  geom_histogram(binwidth = 5000, color = "black") +
  scale_x_continuous(labels = scales::number_format(scale = 1), limits = c(-200000, 200000)) +
  scale_fill_manual(values = c("dem" = "blue", "rep" = "red")) +
  labs(title = "Count of Party Wins by County in 2016")

elections2020 |>
  mutate(winner = ifelse(diff < 0, "dem", "rep")) |> 
  ggplot(aes(x = diff, fill = winner)) +
  geom_histogram(binwidth = 5000, color = "black") +
  scale_x_continuous(labels = scales::number_format(scale = 1), limits = c(-200000, 200000)) +
  scale_fill_manual(values = c("dem" = "blue", "rep" = "red")) +
  labs(title = "Count of Party Wins by County in 2020")


elections2024 |>
  mutate(winner = ifelse(diff < 0, "dem", "rep")) |> 
  ggplot(aes(x = diff, fill = winner)) +
  geom_histogram(binwidth = 5000, color = "black") +
  scale_x_continuous(labels = scales::number_format(scale = 1), limits = c(-200000, 200000)) +
  scale_fill_manual(values = c("dem" = "blue", "rep" = "red")) +
  labs(title = "Count of Party Wins by County in 2024")

```
These plots show us that republicans consistenly have won more counties in the 2016, 2020, and 2024 presidential elections. This means that not all counties are created equal, since we know that a republican candidate did not win in 2020. That is, a democrat can still win even if they did not win more counties than the republican candidate. This plot demonstrates why we decided not to predict the presidential winner by number of counties. Instead, we decided our outcome to be the winner for each county, since the number of county wins would be a poor predictor of who wins a presidential election. 

```{r, warning=FALSE, message=FALSE}

#2020

finaldata2020 |>
  select(state_name, prop_less_than_hs, prop_hs_grad, prop_some_college_associates, prop_bachelors_higher) |>
  mutate(region = case_when(
    state_name %in% c("Connecticut", "Maine", "Massachusetts", "New Hampshire", "Rhode Island", 
                      "Vermont", "New Jersey", "New York", "Pennsylvania") ~ "Northeast", 
    state_name %in% c("Indiana", "Illinois", "Michigan", "Ohio", "Wisconsin", "Iowa", "Nebraska", 
                      "Kansas", "North Dakota", "Minnesota", "South Dakota", "Missouri") ~ "Midwest", 
    state_name %in% c("Delaware", "District of Columbia", "Florida", "Georgia", "Maryland", "North Carolina", 
                      "South Carolina", "Virginia", "West Virginia", "Alabama", "Kentucky", "Mississippi", 
                      "Tennessee", "Arkansas", "Louisiana", "Oklahoma", "Texas") ~ "South",  
    state_name %in% c("Alaska", "California", "Hawaii", "Oregon", "Washington", "Arizona", "Colorado", "Idaho", "New Mexico", "Montana", "Utah", "Nevada", "Wyoming") ~ "West")) |>
  group_by(region) |> 
  pivot_longer(cols = c(prop_less_than_hs, prop_hs_grad, prop_some_college_associates, prop_bachelors_higher),
               names_to = "education_level", values_to = "proportion") |>
  mutate(proportion_two = proportion / sum(proportion) * 100) |>
ggplot(aes(x = region, y = proportion_two, fill = education_level)) +
  geom_bar(stat = "identity") +
  labs(title = "Education Distribution by Region in 2020", y = "Proportion (%)", x = "Region") +
  scale_y_continuous(labels = scales::percent) +  
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(axis.text.y = element_blank(),
        axis.title.y = element_blank())

  
```
This graph shows that the northeast region is slightly more educated, with more of the popualtion having a higher amount of people with a bachelors degree. We included education as a predictor because different counties from different states may be more educated. This could change voting patterns. Education level could be a helpful predictor in presidential elections.  

```{r, warning=FALSE, message=FALSE}

# Choosing Population Variables
finaldata2020 |>
  ggplot() +
  geom_point(aes(x = total_population,
                 y = land_area),
             alpha = 0.1,
             color = "pink") + 
  geom_smooth(mapping = aes(x = total_population,
                            y = land_area),
              method = "lm",
              se = FALSE,
              color = "black",
              linetype = "dashed") +
  labs(title = "Land Area and Total Population")
  
```
As population increases, the land area increases, on average. This graph does show though, that certain areas have a higher population and lower land mass. These are urban areas. This graph demonstrates the reason why we chose to use population density as a predictor rather than total population or land area alone. Those measurments alone do not precisely capture all facets of the living situation certain counties are in.

```{r, warning=FALSE, message=FALSE}

# Choosing Economic Variables
finaldata2020 |>
  ggplot() +
  geom_point(aes(x = unemployment_rate,
                 y = median_income,
                 color = poverty_rate > 0.2),
             alpha = 0.1) + 
  geom_smooth(mapping = aes(x = unemployment_rate,
                            y = median_income),
              method = "lm",
              se = FALSE,
              color = "black",
              linetype = "dashed") +
  labs(title = "Unemployment Rate and Median income") +
  scale_color_manual(values = c("TRUE" = "red", "FALSE" = "green")) 

```
This graph shows that as unemployment rate increases, median income decreases. This is as expected. This graph also shows, however, that some counties have higher incomes and a still some citizens unemployed. Thus, we decided to include both in our model to better represent the level of economic disadvantage of a community. This graph also shows that counties with a high poverty rate, which we defined as 20% (based on the USDA, Economic Research Service’s (ERS) Poverty Area Measures), may also have a lower unemployment rate. Additionally, some counties that have a high poverty rate actually have a median income that falls above the summary line, meaning they have a relatively higher median income. The fact that these three measures of economic standing alone do not perfectly predict where counties may fall in the other economic categories demonstrates why we include all three measures of economic standing. By including all these measures, we capture the true economic situation in these counties. Hopefully, including all three will improve our models. 

```{r, warning=FALSE, message=FALSE}

# Choosing inequality estimators
finaldata2020 |>
  mutate(region = case_when(
    state_name %in% c("Connecticut", "Maine", "Massachusetts", "New Hampshire", "Rhode Island", 
                      "Vermont", "New Jersey", "New York", "Pennsylvania") ~ "Northeast", 
    state_name %in% c("Indiana", "Illinois", "Michigan", "Ohio", "Wisconsin", "Iowa", "Nebraska", 
                      "Kansas", "North Dakota", "Minnesota", "South Dakota", "Missouri") ~ "Midwest", 
    state_name %in% c("Delaware", "District of Columbia", "Florida", "Georgia", "Maryland", "North Carolina", 
                      "South Carolina", "Virginia", "West Virginia", "Alabama", "Kentucky", "Mississippi", 
                      "Tennessee", "Arkansas", "Louisiana", "Oklahoma", "Texas") ~ "South",  
    state_name %in% c("Alaska", "California", "Hawaii", "Oregon", "Washington", "Arizona", "Colorado", "Idaho", "New Mexico", "Montana", "Utah", "Nevada", "Wyoming") ~ "West")) |>
  group_by(region) |> 
  ggplot() +
  geom_point(aes(x = poverty_rate,
                 y = gini),
             alpha = 0.1,
             color = "pink") + 
  geom_smooth(mapping = aes(x = poverty_rate,
                            y = gini,
                            group = region,
                            color = region),
              method = "lm",
              se = FALSE,
              linetype = "dashed")
  
  
```
This graph shows that for all regions, poverty rate increasing is associated with increases in the gini index. This makes sense, that more people living below the poverty line is associated with an increase in the income inequality of a county. This is important to note, that these two variables may be more correlated. When we are making our model, we may want to make sure highly correlated variables are not included at the same time.

NEED TO JUSTIFY SPECIFIC RACE VARIABLES, AGE, FOREIGN BORN, UNDOCUMENTED, MEDIAN HOUSING COST

## V-fold cross-validation

```{r, warning=FALSE, message=FALSE}

train_folds <- vfold_cv(data = train, v = 10)

```

# Testing models using 2020 data

## Create a recipe

```{r, warning=FALSE, message=FALSE}

recipe <-
  recipe(diff_current ~ diff_previous + prop_less_than_hs + prop_bachelors_higher + prop_18_to_24 + prop_65_years_older + prop_white + prop_black + prop_hispanic + poverty_rate + unemployment_rate + male_ratio_per_100_females + median_age + median_income + gini + median_housing_costs + prop_foreign_born_citizen + prop_undocumented + population_density,
         data = train) |>
  step_impute_knn(all_predictors()) |>
  step_corr(all_predictors()) |>
  step_log(median_income, median_housing_costs) |>
  step_interact(terms =  ~ prop_black*gini)

```

Justifications:

step_impute_knn(all_predictors())

step_corr(all_predictors())

step_log(median_income, median_housing_costs)

step_mutate(squared_median_age = median_age\^2)

step_interact(terms = \~ prop_black\*gini): we expect that the relationship between income inequality and voting outcomes (margins) changes based on the proportion of a county that is black

## LASSO

```{r, warning=FALSE, message=FALSE}

lasso_spec <- linear_reg(penalty = 0.1, mixture = 1) |>
    set_mode(mode = "regression") |>
    set_engine(engine = "glmnet")

lasso_wf <- workflow() |>
    add_recipe(recipe) |>
    add_model(lasso_spec)

lasso_resamples <- fit_resamples(
  lasso_wf,
  resamples = train_folds)

lasso_resamples |>
  collect_metrics()

```

## Decision Tree

```{r, warning=FALSE, message=FALSE}

set.seed(20201020)

# creating a recipe

recipe_decision <- train |> 
  recipe(diff_current ~ diff_previous + prop_less_than_hs + prop_bachelors_higher + prop_18_to_24 + prop_65_years_older + prop_white + prop_black + prop_hispanic + poverty_rate + unemployment_rate + male_ratio_per_100_females + median_age + median_income + gini + median_housing_costs + prop_foreign_born_citizen + prop_undocumented + population_density) |> 
  step_impute_knn(all_predictors()) |>
  step_corr(all_predictors()) |>
  step_log(median_income, median_housing_costs, -all_outcomes()) |>
  step_interact(terms =  ~ prop_black*gini)

# creating a model

model_decision <- 
  decision_tree() |> 
  set_engine(engine = "rpart") |> 
  set_mode(mode = "regression")

# creating a workflow

workflow_decision <-
  workflow() |> 
  add_recipe(recipe_decision) |> 
  add_model(model_decision)

# fitting the data 

fit_decision <- workflow_decision |> 
  fit(data = finaldata2020)

# generate predictions

predictions_decision <- bind_cols(
  test,
  predict(object = fit_decision,
          new_data = test)
)

# evaluate the model

truth_decision <- predictions_decision |> 
  group_by(state_name) |> 
  summarize(sum_diff_current = sum(diff_current))

pred_decision <- predictions_decision |> 
  group_by(state_name) |> 
  summarize(sum_diff_prediction = sum(.pred))

finalmodel_decision <- truth_decision |> 
  left_join(pred_decision, by = "state_name") |> 
  mutate(difference_in_prediction = sum_diff_prediction - sum_diff_current,
         actual_winner = if_else(sum_diff_current < 0, "DEM", "GOP"),
         predicted_winner = if_else(sum_diff_prediction < 0, "DEM", "GOP"),
         correct_prediction = if_else(actual_winner == predicted_winner, 1, 0))

# loading electoral college

electoral_college <- read_csv("data/Electoral_College.csv") |> 
  select(!Abb_State) |> 
  rename(state_name = Full_State)

# merging decision tree final model with electoral college

finalmodel_decision <- finalmodel_decision |> 
  left_join(electoral_college, by = "state_name")

# calculating presidential race winners

finalmodel_decision |> 
  group_by(actual_winner) |> 
  summarize(sum_electoral_votes = sum(Electoral_College_Votes)) # actual winner was democrat with 316 electoral votes

finalmodel_decision |> 
  group_by(predicted_winner) |> 
  summarize(sum_electoral_votes = sum(Electoral_College_Votes)) # predicted winner was democrat with 274 electoral votes
  
```

## KNN

```{r, warning=FALSE, message=FALSE}

# check to see if there are any na values

colSums(is.na(train)) > 0

folds_knn <- vfold_cv(data = train, v = 10, repeats = 5)

# construct the model

model_knn <- 
  nearest_neighbor(neighbors = tune()) |> 
  set_engine(engine = "kknn") |> 
  set_mode(mode = "regression")

# add the grid

grid_knn <- grid_regular(neighbors(range = c(1,99)),
                         levels = 10)

# same recipe

recipe_knn <- train |> 
  recipe(diff_current ~ diff_previous + prop_less_than_hs + prop_bachelors_higher + prop_18_to_24 + prop_65_years_older + prop_white + prop_black + prop_hispanic + poverty_rate + unemployment_rate + male_ratio_per_100_females + median_age + median_income + gini + median_housing_costs + prop_foreign_born_citizen + prop_undocumented + population_density) |> 
  step_impute_knn(all_predictors()) |>
  step_impute_knn(all_outcomes()) |>
  step_log(median_income, median_housing_costs, -all_outcomes()) |>
  step_interact(terms =  ~ prop_black*gini)

# create a workflow

workflow_knn <-
  workflow() |> 
  add_recipe(recipe = recipe_knn) |> 
  add_model(spec = model_knn)

res_knn <-
  workflow_knn |>  
  tune_grid(
    resample = folds_knn,
    grid = grid_knn,
    metrics = metric_set(rmse))

# collect rmse metrics

res_knn |> 
  collect_metrics()

# show best model

res_knn |> 
  show_best()

res_knn |> 
  autoplot()

# fit final knn model

final_wf_knn <-
  workflow_knn |> 
  finalize_workflow(select_best(res_knn))

final_fit_knn <-
  final_wf_knn |> 
  last_fit(modeling_sample)

final_fit_knn |> 
  collect_metrics
  
```

(Insert model here) has the lowest out of sample error rate

# Final model estimation on 2024 data
