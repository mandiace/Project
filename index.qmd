---
title: "Final Project"
author: "Mandi Acevedo, Kevin Velasco, Bela Walkin"
format: html
editor: visual
---

```{r, warning=FALSE, message=FALSE}
library(httr)
library(jsonlite)
library(modelr)
library(parsnip)
library(patchwork)
library(recipes)
library(scales)
library(sf)
library(stringr)
library(tidycensus)
library(tidymodels)
library(tidyr)
library(tidyverse)
library(tigris)

```

# Data cleaning & structuring

## 2020/2016 data

### Download 2020/2016 election results data

Data on 2016 and 2020 U.S. presidential elections results come from [this public GitHub repository](https://github.com/tonmcg/US_County_Level_Election_Results_08-24), which compiles results from reputable sources, including Politico and the New York Times. This data includes margins (out outcome variable).

```{r, warning=FALSE, message=FALSE}

elections2016  <- read_csv("data/2016_US_County_Level_Presidential_Results.csv")

elections2020  <- read_csv("data/2020_US_County_Level_Presidential_Results.csv")

```

### Merge 2020/2016 data into single file

```{r}

elections2020 <- elections2020 |>
  mutate(county_fips = as.character(str_remove(county_fips, "^0"))) 

elections2016 <- elections2016 |>
  mutate(county_fips = as.character(combined_fips)) |>
  select(-combined_fips, -diff) |> 
  mutate(diff = (votes_gop - votes_dem))
  

elections2020_2016 <- left_join(elections2020,
                                elections2016,
                                by = "county_fips")

colnames(elections2020_2016) <- gsub("\\.x$", "_current", colnames(elections2020_2016))
colnames(elections2020_2016) <- gsub("\\.y$", "_previous", colnames(elections2020_2016))

elections2020_2016 <- elections2020_2016 |>
  mutate(county_name = county_name_current) |>
  select(-county_name_previous, -county_name_current)

```

### Download county size data 

```{r, warning=FALSE, message=FALSE}

county_size <- read_csv("data/LND01.csv") |> 
  select(STCOU,
         LND010190D) |> 
  rename(geoid = STCOU,
         land_area = LND010190D) |> 
  mutate(geoid = sub("^0+", "", geoid))

# manually input data for Connecticut county-equivalents, as Census switched from using counties to Connecticut's Councils of Government divisions in 2022.

ct_county_eq_size <- data.frame(
  geoid = c(9110, 9120, 9130, 9140, 9150, 9160, 9170, 9180, 9190),
  land_area = c(1027.3, 140.2, 424.1, 412.8, 553.9, 786.6, 367.2, 598.1, 532.1)
) |> 
  mutate(geoid = as.character(geoid))

county_size <- county_size |> 
  bind_rows(ct_county_eq_size)

```

### Download county and state geospatial data

```{r}

counties_geospatial <-  counties(cb = TRUE) 

state_geospatial <- states(cb = TRUE)

```


### Download 2019 predictor data via API

We use 2019 predictor data rather than 2020 due to ACS availability. Many demographic variables (racial compositions, age distribution, etc.) do not change significantly year-on-year, so 2019 data should suffice for our purposes.

```{r, warning=FALSE, message=FALSE}

# download county demographic data

predictors2019 <- get_acs(dataset = "acs5",
                    year = 2019,
                    geography = "county",
                    variables = c(
                      # educational attainment
                      count18to24 = "S1501_C01_001",
                      count24to34 = "S1501_C01_016",
                      count35to44 = "S1501_C01_019",
                      count45to64 = "S1501_C01_022",
                      count65over = "S1501_C01_025",
                      countlessthanhs = "S1501_C01_002",
                      counthsgrad = "S1501_C01_003",
                      countsomecollegeassociates = "S1501_C01_004",
                      countbachhigher = "S1501_C01_005",
                      # total population
                      totalpopulation = "B01003_001",
                      # demographic information
                      maleratioper100females = "DP05_0004",
                      medianage = "DP05_0018",
                      countwhite = "DP05_0037",
                      countblack = "DP05_0038",
                      counthispanic = "DP05_0071",
                      # income
                      medianincome = "S1901_C01_012",
                      medianhhincome = "S1901_C02_012",
                      countbelowpoverty = "S1701_C02_001",
                      medianhousingcosts = "S2503_C01_024",
                      gini = "B19083_001",
                      # employment
                      countlaborforce16plus = "DP03_0002",
                      countunemployedinlaborforce16plus = "DP03_0005",
                      # foreign born
                      countforeignborncitizen = "B05002_013",
                      countforeignbornundocumented = "B05002_021")) |> 
  select(!moe) |> 
  pivot_wider(names_from = variable,
              values_from = estimate)
                      
predictors2019 <- predictors2019 |> 
  mutate(count18over = count18to24 + count24to34 + count35to44 + count45to64 + count65over,
         prop_less_than_hs = countlessthanhs / count18to24,
         prop_hs_grad = counthsgrad / count18to24,
         prop_some_college_associates = countsomecollegeassociates / count18to24,
         prop_bachelors_higher = countbachhigher / count18to24,
         prop_18_to_24 = count18to24 / totalpopulation,
         prop_65_years_older = count65over / totalpopulation,
         prop_white = countwhite / totalpopulation,
         prop_black = countblack / totalpopulation,
         prop_hispanic = counthispanic / totalpopulation,
         poverty_rate = countbelowpoverty / totalpopulation,
         unemployment_rate = countunemployedinlaborforce16plus / countlaborforce16plus,
         prop_foreign_born_citizen = countforeignborncitizen / totalpopulation,
         prop_undocumented = countforeignbornundocumented / totalpopulation,
         year = 2019) |> 
  rename(male_ratio_per_100_females = maleratioper100females,
         median_age = medianage,
         median_income = medianincome, 
         median_housing_costs = medianhousingcosts,
         total_population = totalpopulation,
         geoid = GEOID,
         name = NAME) |> 
  select(geoid,
         name,
         total_population,
         prop_less_than_hs,
         prop_hs_grad,
         prop_some_college_associates,
         prop_bachelors_higher,
         prop_18_to_24,
         prop_65_years_older,
         prop_white,
         prop_black,
         prop_hispanic,
         poverty_rate,
         unemployment_rate,
         male_ratio_per_100_females,
         median_age,
         median_income,
         gini,
         median_housing_costs,
         prop_foreign_born_citizen,
         prop_undocumented) |> 
  mutate(geoid = sub("^0+", "", geoid))

# merging county size predictors and calculating population density

predictors2019 <- left_join(x = predictors2019,
                      y = county_size,
                      by = "geoid") |> 
  mutate(land_area = as.numeric(land_area),
         population_density = total_population / land_area)

```

### Merge elections & predictor dataframes

```{r}

predictors2019 <- predictors2019 |>
  mutate(county_fips = geoid) |>
  select(-name, -geoid)
  
  
finaldata2020 <- left_join(x = elections2020_2016,
                      y = predictors2019,
                      by = "county_fips")

```

### Rectify missing data

The only observations in our dataset with missing variables are observations in the state of Alaska. The elections dataset divides Alaska into its 40 state-level congressional districts, but our predictor dataset divides Alaska by its 30 boroughs and census areas (Alaskan county-equivalents).

We are thus removing all Alaskan observations from our dataset, limiting the external validity of our model.

There is also a single observation in South Dakota that is missing data. We drop this variable rather than impute for the sake of time, since a single observation should not significantly impact results.

```{r}

finaldata2020 |>
  filter(if_any(everything(), is.na))

finaldata2020 <- finaldata2020 |>
  filter(state_name != "Alaska") |>
  filter(county_fips != 46102)

finaldata2020 |>
  filter(if_any(everything(), is.na)) ## confirmed no missing data

```

## 2024/2020 data

### Download 2024 election results data

```{r, warning=FALSE, message=FALSE}

elections2024  <- read_csv("data/2024_US_County_Level_Presidential_Results.csv")

```

### Rolling up DC elections data into a single row

DC data is presented by ward in the elections dataset, but not the 2022 predictors dataset.

```{r, warning=FALSE, message=FALSE}

dc_data <- elections2024 |>
  filter(state_name == "District of Columbia") |>
  mutate(
    weighted_percent_votes_gop = per_gop * total_votes,
    weighted_percent_votes_dem = per_dem * total_votes,
    weighted_percent_points_diff = per_point_diff * total_votes
  ) |> 
  summarize(
    county_fips = 11001,
    votes_gop = sum(votes_gop),
    votes_dem = sum(votes_dem),
    total_votes = sum(total_votes),
    diff = sum(diff),
    per_gop = sum(weighted_percent_votes_gop) / sum(total_votes),
    per_dem = sum(weighted_percent_votes_dem) / sum(total_votes),
    per_point_diff = sum(weighted_percent_points_diff) / sum(total_votes),
    state_name = "District of Columbia",
    county_name = "District of Columbia"
  ) |> 
  mutate(county_fips = as.character(county_fips))

```

### Merge 2024/2020 elections data into single file

```{r, warning=FALSE, message=FALSE}

elections2024 <- elections2024 |> 
  filter(!county_fips %in% c(11001, 11002, 11003, 11004, 11005, 11006, 11007, 11008)) |> # data inputted manually from census burea information
  bind_rows(dc_data)

# rest of merge

elections2024 <- elections2024 |>
  mutate(county_fips = as.character(str_remove(county_fips, "^0"))) 

elections2024_2020 <- left_join(elections2024,
                                elections2020,
                                by = "county_fips")

colnames(elections2024_2020) <- gsub("\\.x$", "_current", colnames(elections2024_2020))
colnames(elections2024_2020) <- gsub("\\.y$", "_previous", colnames(elections2024_2020))

elections2024_2020 <- elections2024_2020 |>
  mutate(county_name = county_name_current) |>
  select(-county_name_previous, -county_name_current)

elections2024_2020 <- elections2024_2020 |>
  mutate(state_name = state_name_current) |>
  select(-state_name_previous, -state_name_current)
```

### Download 2022 predictor data via API

Similar to our 2020 dataset, we use 2022 predictor data rather than 2024 due to ACS availability. Many demographic variables (racial compositions, age distribution, etc.) do not change significantly year-on-year, so 2024 data should suffice for our purposes.

```{r, warning=FALSE, message=FALSE}

# download county demographic data

predictors2022 <- get_acs(dataset = "acs5",
                    year = 2022,
                    geography = "county",
                    variables = c(
                      # educational attainment
                      count18to24 = "S1501_C01_001",
                      count24to34 = "S1501_C01_016",
                      count35to44 = "S1501_C01_019",
                      count45to64 = "S1501_C01_022",
                      count65over = "S1501_C01_025",
                      countlessthanhs = "S1501_C01_002",
                      counthsgrad = "S1501_C01_003",
                      countsomecollegeassociates = "S1501_C01_004",
                      countbachhigher = "S1501_C01_005",
                      # total population
                      totalpopulation = "B01003_001",
                      # demographic information
                      maleratioper100females = "DP05_0004",
                      medianage = "DP05_0018",
                      countwhite = "DP05_0037",
                      countblack = "DP05_0038",
                      counthispanic = "DP05_0071",
                      # income
                      medianincome = "S1901_C01_012",
                      medianhhincome = "S1901_C02_012",
                      countbelowpoverty = "S1701_C02_001",
                      medianhousingcosts = "S2503_C01_024",
                      gini = "B19083_001",
                      # employment
                      countlaborforce16plus = "DP03_0002",
                      countunemployedinlaborforce16plus = "DP03_0005",
                      # foreign born
                      countforeignborncitizen = "B05002_013",
                      countforeignbornundocumented = "B05002_021")) |> 
  select(!moe) |> 
  pivot_wider(names_from = variable,
              values_from = estimate)

predictors2022 <- predictors2022 |> 
  mutate(count18over = count18to24 + count24to34 + count35to44 + count45to64 + count65over,
         prop_less_than_hs = countlessthanhs / count18to24,
         prop_hs_grad = counthsgrad / count18to24,
         prop_some_college_associates = countsomecollegeassociates / count18to24,
         prop_bachelors_higher = countbachhigher / count18to24,
         prop_18_to_24 = count18to24 / totalpopulation,
         prop_65_years_older = count65over / totalpopulation,
         prop_white = countwhite / totalpopulation,
         prop_black = countblack / totalpopulation,
         prop_hispanic = counthispanic / totalpopulation,
         poverty_rate = countbelowpoverty / totalpopulation,
         unemployment_rate = countunemployedinlaborforce16plus / countlaborforce16plus,
         prop_foreign_born_citizen = countforeignborncitizen / totalpopulation,
         prop_undocumented = countforeignbornundocumented / totalpopulation,
         year = 2022) |> 
  rename(male_ratio_per_100_females = maleratioper100females,
         median_age = medianage,
         median_income = medianincome, 
         median_housing_costs = medianhousingcosts,
         total_population = totalpopulation,
         geoid = GEOID,
         name = NAME) |> 
  select(geoid,
         name,
         total_population,
         prop_less_than_hs,
         prop_hs_grad,
         prop_some_college_associates,
         prop_bachelors_higher,
         prop_18_to_24,
         prop_65_years_older,
         prop_white,
         prop_black,
         prop_hispanic,
         poverty_rate,
         unemployment_rate,
         male_ratio_per_100_females,
         median_age,
         median_income,
         gini,
         median_housing_costs,
         prop_foreign_born_citizen,
         prop_undocumented) |> 
  mutate(geoid = sub("^0+", "", geoid))

# merging county size predictors and calculating population density

predictors2022 <- left_join(x = predictors2022,
                      y = county_size,
                      by = "geoid") |> 
  mutate(land_area = as.numeric(land_area),
         population_density = total_population / land_area)

```

Why did we choose these predictors? 

According to a study conducted by Kulachi et al. (2023), voting behavior is very dynamic. People's voting patterns depend on a culmination of numerous factors. Some factors shown to impact voting behavior that are included in this analysis are economic, gender, ethnicity and race, and age variables. Thus, we pulled predictors within these groupings. Other factors that have been shown to influence voting behaviors, like health care experiences, media influences, are difficult to estimate at an individual level. Thus, these are much more difficult to estimate at a county level. Due to the complexities in estimating these variables and limited data access, we do not include these variables in our analysis. 

### Merge elections & predictor dataframes

```{r, warning=FALSE, message=FALSE}

predictors2022 <- predictors2022 |>
  mutate(county_fips = geoid) |>
  select(-name, -geoid)
  
  
finaldata2024 <- left_join(x = elections2024_2020,
                      y = predictors2022,
                      by = "county_fips") 

```

### Rectify missing data

Again, we remove Alaskan observations and the singular South Dakota observation, for the same reasons we did in the 2020 data.

We also drop Kenedy and Loving Counties, both in Texas, as they are two of the smallest counties in the U.S. with a permanent population. Observations are missing median income and housing cost data.

Beginning in 2022, Connecticut switched from using counties to using Councils of Government for statistical reporting purposes. The new county-equivalents do not match the previous boundaries of counties. Connecticut is thus missing 2020 elections results data, which will be rectified via imputation in our recipe.

```{r}

finaldata2024 |>
  filter(if_any(everything(), is.na))

finaldata2024 <- finaldata2024 |>
  filter(state_name != "Alaska") |>
  filter(county_fips != 46102 &
           county_fips != 48261 &
           county_fips != 48301)

finaldata2024 |>
  filter(if_any(everything(), is.na)) ## confirmed no missing data outside of Connecticut 2020 voting data

```

# Set up testing environment using 2020 data

## Initial split

```{r}

set.seed(12071999)

modeling_sample <- initial_split(finaldata2020)

train <- training(modeling_sample)
test <- testing(modeling_sample)

```

## Exploratory analysis

```{r, warning=FALSE, message=FALSE}

theme_set(theme_minimal())

elections2020 |>
  mutate(winner = ifelse(diff < 0, "dem", "rep")) |> 
  ggplot(aes(x = diff, fill = winner)) +
  geom_histogram(binwidth = 5000, color = "black") +
  scale_x_continuous(labels = scales::number_format(scale = 1), limits = c(-200000, 200000)) +
  scale_fill_manual(values = c("dem" = "blue", "rep" = "red")) +
  labs(title = "Count of Party Wins by County Margin in 2020")

finaldata2020 |>
  mutate(pop_size_decile = ntile(total_population, 10)) |>
  mutate(winner = ifelse(diff_current < 0, "dem", "rep")) |>
  group_by(pop_size_decile) |>
  summarise("dem wins" = sum(winner == "dem"),
            "rep wins" = sum(winner == "rep"),
            "share dem wins" = sum(winner == "dem") / n())

```

Republicans won more counties than Democrats in the 2020 presidential election, but the Democratic tail of the distribution is much longer, indicating that large margins happened more often in counties that Democrats won than in counties that Republicans won. We know that a Republican candidate did not win in 2020. This implies that while the Republican candidate won more counties overall, Democrats disproportionately win counties with large populations. This is demonstrated in our table. In 2020, the Republican candidate won the significant majority of all counties with a below-90th percentile population size. However, the Democratic candidate won about 68% the largest 10% of counties in the nation.

This plot also demonstrates why we decided not to model a binary outcome variable capturing whether a Republican won in each county, as such a model will be biased towards Republicans and is not useful in informing national-level winners. Instead, we chose to use margins as our outcome variable, which captures the same information as a binary winner variable while also potentially proving more useful for national-level predictions.


```{r, warning=FALSE, message=FALSE}

#2020

finaldata2020 |>
  select(state_name, prop_less_than_hs, prop_hs_grad, prop_some_college_associates, prop_bachelors_higher, diff_current) |>
  mutate(winner = ifelse(diff_current < 0, "Dem", "Rep")) |> 
  group_by(winner) |> 
  pivot_longer(cols = c(prop_less_than_hs, prop_hs_grad, prop_some_college_associates, prop_bachelors_higher),
               names_to = "education_level", values_to = "proportion") |>
  mutate(proportion_two = proportion / sum(proportion) * 100) |>
ggplot(aes(x = winner, y = proportion_two, fill = education_level)) +
  geom_bar(stat = "identity") +
  labs(title = "Education Distribution by County Winner in 2020", y = "Proportion (%)", x = "Winner") +
  scale_y_continuous(labels = scales::percent) +  
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(axis.text.y = element_blank(),
        axis.title.y = element_blank())
  
```
This graph suggests that counties who voted Democratic in 2020 had a higher number of residents with some college education. We capture educational attainment in the model using a number of predictors, as the leftward political shift of college-educated individuals in recent decades has made educational patterns a potentially useful indicator for voting outcomes.

```{r, warning=FALSE, message=FALSE}

# Choosing Population Variables
finaldata2020 |>
  ggplot() +
  geom_point(aes(x = total_population,
                 y = land_area),
             alpha = 0.1,
             color = "pink") + 
  geom_smooth(mapping = aes(x = total_population,
                            y = land_area),
              method = "lm",
              se = FALSE,
              color = "black",
              linetype = "dashed") +
  labs(title = "Land Area and Total Population")
  
```
As population increases, the land area increases, on average. This graph does show though, that certain areas have a higher population and lower land mass. These are urban areas. This graph demonstrates the reason why we chose to use population density as a predictor rather than total population or land area alone. Those measurments alone do not precisely capture all facets of the living situation certain counties are in.

```{r, warning=FALSE, message=FALSE}

# Choosing Economic Variables
finaldata2020 |>
  ggplot() +
  geom_point(aes(x = unemployment_rate,
                 y = diff_current,
                 color = poverty_rate > 0.2),
             alpha = 0.2) + 
  geom_smooth(mapping = aes(x = unemployment_rate,
                            y = median_income),
              method = "lm",
              se = FALSE,
              color = "black",
              linetype = "dashed") +
  labs(title = "Unemployment Rate and Margin") +
  scale_y_continuous(labels = scales::number_format(scale = 1), limits = c(-200000, 200000)) +
  scale_color_manual(values = c("TRUE" = "red", "FALSE" = "green")) 

```
This graph shows that as unemployment rate in a county increases, the Democratic candidate is more likely to win (Democrat win = negative margin). Counties with higher unemployment rates are also more likely to fall below the poverty line, which we defined as 20% (based on the USDA, Economic Research Service’s (ERS) Poverty Area Measures).  

```{r, warning=FALSE, message=FALSE}

# Choosing inequality estimators
finaldata2020 |>
  mutate(winner = ifelse(diff_current < 0, "Dem", "Rep")) |> 
  group_by(winner) |> 
  ggplot() +
  geom_point(aes(x = poverty_rate,
                 y = gini),
             alpha = 0.2,
             color = "pink") + 
  geom_smooth(mapping = aes(x = poverty_rate,
                            y = gini,
                            group = winner,
                            color = winner),
              method = "lm",
              se = FALSE,
              linetype = "dashed")
  
```
This graph shows that for all regions, poverty rate increasing is associated with increases in the gini index, a measure for income inequality. This makes sense, that more people living below the poverty line is associated with an increase in the income inequality of a county. This is important to note, that these two variables may be more correlated. When we are making our model, we may want to make sure highly correlated variables are not included at the same time. 

NEED TO JUSTIFY SPECIFIC RACE VARIABLES, AGE, FOREIGN BORN, UNDOCUMENTED, MEDIAN HOUSING COST

## V-fold cross-validation

```{r, warning=FALSE, message=FALSE}

train_folds <- vfold_cv(data = train, v = 10)

```

# Testing models using 2020 data

## Create a recipe

```{r, warning=FALSE, message=FALSE}

recipe <-
  recipe(diff_current ~ diff_previous + prop_less_than_hs + prop_bachelors_higher + prop_18_to_24 + prop_65_years_older + prop_white + prop_black + prop_hispanic + poverty_rate + unemployment_rate + male_ratio_per_100_females + median_age + median_income + gini + median_housing_costs + prop_foreign_born_citizen + prop_undocumented + population_density + total_population,
         data = train) |>
  step_impute_knn(all_predictors()) |>
  step_corr(all_predictors()) |>
  step_log(median_income, median_housing_costs) |>
  step_interact(terms =  ~ prop_black*gini)

```

Justifications:

step_impute_knn(all_predictors())

step_corr(all_predictors())

step_log(median_income, median_housing_costs)

step_mutate(squared_median_age = median_age\^2)

step_interact(terms = \~ prop_black\*gini): we expect that the relationship between income inequality and voting outcomes (margins) changes based on the proportion of a county that is black

## LASSO

```{r, warning=FALSE, message=FALSE}

set.seed(12071999)

lasso_spec <- linear_reg(penalty = tune(), 
                         mixture = 1) |>
    set_mode(mode = "regression") |>
    set_engine(engine = "glmnet")

lasso_wf <- workflow() |>
    add_recipe(recipe) |>
    add_model(lasso_spec)

lasso_grid <- grid_regular(
  penalty(range = c(0, 15)),
  levels = 5)

lasso_resamples <- lasso_wf |>
  tune_grid(resamples = train_folds,
            grod = lasso_grid)

lasso_resamples |>
  collect_metrics(type = "wide")

show_best(lasso_resamples)

```

## Decision Tree

```{r, warning=FALSE, message=FALSE}

set.seed(12071999)

# creating a recipe

recipe_decision <- train |> 
  recipe(diff_current ~ diff_previous + prop_less_than_hs + prop_bachelors_higher + prop_18_to_24 + prop_65_years_older + prop_white + prop_black + prop_hispanic + poverty_rate + unemployment_rate + male_ratio_per_100_females + median_age + median_income + gini + median_housing_costs + prop_foreign_born_citizen + prop_undocumented + population_density) |> 
  step_impute_knn(all_predictors()) |>
  step_corr(all_predictors()) |>
  step_log(median_income, median_housing_costs, -all_outcomes()) |>
  step_interact(terms =  ~ prop_black*gini)

# creating a model

model_decision <- 
  decision_tree() |> 
  set_engine(engine = "rpart") |> 
  set_mode(mode = "regression")

# creating a workflow

workflow_decision <-
  workflow() |> 
  add_recipe(recipe_decision) |> 
  add_model(model_decision)

# fitting the data 

fit_decision <- workflow_decision |> 
  fit(data = finaldata2020)

# generate predictions

predictions_decision <- bind_cols(
  test,
  predict(object = fit_decision,
          new_data = test)
)

# evaluate the model

truth_decision <- predictions_decision |> 
  group_by(state_name) |> 
  summarize(sum_diff_current = sum(diff_current))

pred_decision <- predictions_decision |> 
  group_by(state_name) |> 
  summarize(sum_diff_prediction = sum(.pred))

finalmodel_decision <- truth_decision |> 
  left_join(pred_decision, by = "state_name") |> 
  mutate(difference_in_prediction = sum_diff_prediction - sum_diff_current,
         actual_winner = if_else(sum_diff_current < 0, "DEM", "GOP"),
         predicted_winner = if_else(sum_diff_prediction < 0, "DEM", "GOP"),
         correct_prediction = if_else(actual_winner == predicted_winner, 1, 0))

# loading electoral college

electoral_college <- read_csv("data/Electoral_College.csv") |> 
  select(!Abb_State) |> 
  rename(state_name = Full_State)

# merging decision tree final model with electoral college

finalmodel_decision <- finalmodel_decision |> 
  left_join(electoral_college, by = "state_name")

# calculating presidential race winners

finalmodel_decision |> 
  group_by(actual_winner) |> 
  summarize(sum_electoral_votes = sum(Electoral_College_Votes)) # actual winner was democrat with 316 electoral votes

finalmodel_decision |> 
  group_by(predicted_winner) |> 
  summarize(sum_electoral_votes = sum(Electoral_College_Votes)) # predicted winner was democrat with 274 electoral votes

# constructing electoral map by county


  
```

## KNN

```{r, warning=FALSE, message=FALSE}

set.seed(12071999)

# check to see if there are any na values

colSums(is.na(train)) > 0

folds_knn <- vfold_cv(data = train, v = 10, repeats = 5)

# construct the model

model_knn <- 
  nearest_neighbor(neighbors = tune()) |> 
  set_engine(engine = "kknn") |> 
  set_mode(mode = "regression")

# add the grid

grid_knn <- grid_regular(neighbors(range = c(1,99)),
                         levels = 10)

# same recipe

recipe_knn <- train |> 
  recipe(diff_current ~ diff_previous + prop_less_than_hs + prop_bachelors_higher + prop_18_to_24 + prop_65_years_older + prop_white + prop_black + prop_hispanic + poverty_rate + unemployment_rate + male_ratio_per_100_females + median_age + median_income + gini + median_housing_costs + prop_foreign_born_citizen + prop_undocumented + population_density) |> 
  step_impute_knn(all_predictors()) |>
  step_impute_knn(all_outcomes()) |>
  step_log(median_income, median_housing_costs, -all_outcomes()) |>
  step_interact(terms =  ~ prop_black*gini)

# create a workflow

workflow_knn <-
  workflow() |> 
  add_recipe(recipe = recipe_knn) |> 
  add_model(spec = model_knn)

res_knn <-
  workflow_knn |>  
  tune_grid(
    resample = folds_knn,
    grid = grid_knn,
    metrics = metric_set(rmse))

# collect rmse metrics

res_knn |> 
  collect_metrics()

# show best model

res_knn |> 
  show_best()

res_knn |> 
  autoplot()

# fit final knn model

final_wf_knn <-
  workflow_knn |> 
  finalize_workflow(select_best(res_knn))

final_fit_knn <-
  final_wf_knn |> 
  last_fit(modeling_sample)

final_fit_knn |> 
  collect_metrics
  
```

(Insert model here) has the lowest out of sample error rate

# Final model estimation on 2024 data
