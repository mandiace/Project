---
title: "Final Project"
author: "Mandi Acevedo, Kevin Velasco, Bela Walkin"
format: html
editor: visual
---

```{r, warning=FALSE, message=FALSE}
library(dplyr)
library(httr)
library(jsonlite)
library(modelr)
library(parsnip)
library(recipes)
library(sf)
library(stringr)
library(tidycensus)
library(tidymodels)
library(tidyr)
library(tidyverse)

```

# Data cleaning & structuring

## 2020/2016 data

### Download 2020/2016 election results data

```{r, warning=FALSE, message=FALSE}
elections2016  <- read_csv("data/2016_US_County_Level_Presidential_Results.csv")

elections2020  <- read_csv("data/2020_US_County_Level_Presidential_Results.csv")

```

### Merge 2020/2016 data into single file

```{r}
elections2020 <- elections2020 |>
  mutate(county_fips = as.character(str_remove(county_fips, "^0"))) 

elections2016 <- elections2016 |>
  mutate(county_fips = as.character(combined_fips)) |>
  select(-combined_fips)

elections2020_2016 <- left_join(elections2020,
                                elections2016,
                                by = "county_fips")

colnames(elections2020_2016) <- gsub("\\.x$", "_current", colnames(elections2020_2016))
colnames(elections2020_2016) <- gsub("\\.y$", "_previous", colnames(elections2020_2016))

elections2020_2016 <- elections2020_2016 |>
  mutate(county_name = county_name_current) |>
  select(-county_name_previous, -county_name_current)

```

### Download county size data

```{r, warning=FALSE, message=FALSE}

county_size <- read_csv("data/LND01.csv") |> 
  select(STCOU,
         LND010190D) |> 
  rename(geoid = STCOU,
         land_area = LND010190D) |> 
  mutate(geoid = sub("^0+", "", geoid))

```


### Download 2019 predictor data via API

```{r, warning=FALSE, message=FALSE}

# download county size data

county_size <- read_csv("data/LND01.csv") |> 
  select(STCOU,
         LND010190D) |> 
  rename(geoid = STCOU,
         land_area = LND010190D) |> 
  mutate(geoid = sub("^0+", "", geoid))

# manually inputting data on CT county-equivalents

ct_county_eq_size <- data.frame(
  geoid = c(9110, 9120, 9130, 9140, 9150, 9160, 9170, 9180, 9190),
  land_area = c(1027.3, 140.2, 424.1, 412.8, 553.9, 786.6, 367.2, 598.1, 532.1)
) |> 
  mutate(geoid = as.character(geoid))

county_size <- county_size |> 
  bind_rows(ct_county_eq_size)

# download county demographic data

predictors2019 <- get_acs(dataset = "acs5",
                    year = 2019,
                    geography = "county",
                    variables = c(
                      # educational attainment
                      count18to24 = "S1501_C01_001",
                      count24to34 = "S1501_C01_016",
                      count35to44 = "S1501_C01_019",
                      count45to64 = "S1501_C01_022",
                      count65over = "S1501_C01_025",
                      countlessthanhs = "S1501_C01_002",
                      counthsgrad = "S1501_C01_003",
                      countsomecollegeassociates = "S1501_C01_004",
                      countbachhigher = "S1501_C01_005",
                      # total population
                      totalpopulation = "B01003_001",
                      # demographic information
                      maleratioper100females = "DP05_0004",
                      medianage = "DP05_0018",
                      countwhite = "DP05_0037",
                      countblack = "DP05_0038",
                      counthispanic = "DP05_0071",
                      # income
                      medianincome = "S1901_C01_012",
                      medianhhincome = "S1901_C02_012",
                      countbelowpoverty = "S1701_C02_001",
                      medianhousingcosts = "S2503_C01_024",
                      gini = "B19083_001",
                      # employment
                      countlaborforce16plus = "DP03_0002",
                      countunemployedinlaborforce16plus = "DP03_0005",
                      # foreign born
                      countforeignborncitizen = "B05002_013",
                      countforeignbornundocumented = "B05002_021")) |> 
  select(!moe) |> 
  pivot_wider(names_from = variable,
              values_from = estimate)
                      
predictors2019 <- predictors2019 |> 
  mutate(count18over = count18to24 + count24to34 + count35to44 + count45to64 + count65over,
         prop_less_than_hs = countlessthanhs / count18to24,
         prop_hs_grad = counthsgrad / count18to24,
         prop_some_college_associates = countsomecollegeassociates / count18to24,
         prop_bachelors_higher = countbachhigher / count18to24,
         prop_18_to_24 = count18to24 / totalpopulation,
         prop_65_years_older = count65over / totalpopulation,
         prop_white = countwhite / totalpopulation,
         prop_black = countblack / totalpopulation,
         prop_hispanic = counthispanic / totalpopulation,
         poverty_rate = countbelowpoverty / totalpopulation,
         unemployment_rate = countunemployedinlaborforce16plus / countlaborforce16plus,
         prop_foreign_born_citizen = countforeignborncitizen / totalpopulation,
         prop_undocumented = countforeignbornundocumented / totalpopulation,
         year = 2019) |> 
  rename(male_ratio_per_100_females = maleratioper100females,
         median_age = medianage,
         median_income = medianincome, 
         median_housing_costs = medianhousingcosts,
         total_population = totalpopulation,
         geoid = GEOID,
         name = NAME) |> 
  select(geoid,
         name,
         total_population,
         prop_less_than_hs,
         prop_hs_grad,
         prop_some_college_associates,
         prop_bachelors_higher,
         prop_18_to_24,
         prop_65_years_older,
         prop_white,
         prop_black,
         prop_hispanic,
         poverty_rate,
         unemployment_rate,
         male_ratio_per_100_females,
         median_age,
         median_income,
         gini,
         median_housing_costs,
         prop_foreign_born_citizen,
         prop_undocumented) |> 
  mutate(geoid = sub("^0+", "", geoid))

# merging county size predictors and calculating population density

predictors2019 <- left_join(x = predictors2019,
                      y = county_size,
                      by = "geoid") |> 
  mutate(land_area = as.numeric(land_area),
         population_density = total_population / land_area)

```

### Merge elections & predictor dataframes

```{r}

predictors2019 <- predictors2019 |>
  mutate(county_fips = geoid) |>
  select(-name, -geoid)
  
  
finaldata2020 <- left_join(x = elections2020_2016,
                      y = predictors2019,
                      by = "county_fips") |>
  na.omit()

```

## 2024/2020 data

### Download 2024 election results data

```{r, warning=FALSE, message=FALSE}
elections2024  <- read_csv("data/2024_US_County_Level_Presidential_Results.csv")

```

### Merge 2024/2020 data into single file

```{r, warning=FALSE, message=FALSE}
# fixing dc issue so that data for all wards is in one row

dc_data <- elections2024 |>
  filter(state_name == "District of Columbia") |>
  mutate(
    weighted_percent_votes_gop = per_gop * total_votes,
    weighted_percent_votes_dem = per_dem * total_votes,
    weighted_percent_points_diff = per_point_diff * total_votes
  ) |> 
  summarize(
    county_fips = 11001,
    votes_gop = sum(votes_gop),
    votes_dem = sum(votes_dem),
    total_votes = sum(total_votes),
    diff = sum(diff),
    per_gop = sum(weighted_percent_votes_gop) / sum(total_votes),
    per_dem = sum(weighted_percent_votes_dem) / sum(total_votes),
    per_point_diff = sum(weighted_percent_points_diff) / sum(total_votes),
    state_name = "District of Columbia",
    county_name = "District of Columbia"
  ) |> 
  mutate(county_fips = as.character(county_fips))

elections2024 <- elections2024 |> 
  filter(!county_fips %in% c(11001, 11002, 11003, 11004, 11005, 11006, 11007, 11008)) |> 
  bind_rows(dc_data)

# rest of merge

elections2024 <- elections2024 |>
  mutate(county_fips = as.character(str_remove(county_fips, "^0"))) 

elections2024_2020 <- left_join(elections2024,
                                elections2020,
                                by = "county_fips")

colnames(elections2024_2020) <- gsub("\\.x$", "_current", colnames(elections2024_2020))
colnames(elections2024_2020) <- gsub("\\.y$", "_previous", colnames(elections2024_2020))

elections2024_2020 <- elections2024_2020 |>
  mutate(county_name = county_name_current) |>
  select(-county_name_previous, -county_name_current)

elections2024_2020 <- elections2024_2020 |>
  mutate(state_name = state_name_current) |>
  select(-state_name_previous, -state_name_current)
```

### Download 2022 predictor data via API

```{r, warning=FALSE, message=FALSE}

# download county demographic data

predictors2022 <- get_acs(dataset = "acs5",
                    year = 2022,
                    geography = "county",
                    variables = c(
                      # educational attainment
                      count18to24 = "S1501_C01_001",
                      count24to34 = "S1501_C01_016",
                      count35to44 = "S1501_C01_019",
                      count45to64 = "S1501_C01_022",
                      count65over = "S1501_C01_025",
                      countlessthanhs = "S1501_C01_002",
                      counthsgrad = "S1501_C01_003",
                      countsomecollegeassociates = "S1501_C01_004",
                      countbachhigher = "S1501_C01_005",
                      # total population
                      totalpopulation = "B01003_001",
                      # demographic information
                      maleratioper100females = "DP05_0004",
                      medianage = "DP05_0018",
                      countwhite = "DP05_0037",
                      countblack = "DP05_0038",
                      counthispanic = "DP05_0071",
                      # income
                      medianincome = "S1901_C01_012",
                      medianhhincome = "S1901_C02_012",
                      countbelowpoverty = "S1701_C02_001",
                      medianhousingcosts = "S2503_C01_024",
                      gini = "B19083_001",
                      # employment
                      countlaborforce16plus = "DP03_0002",
                      countunemployedinlaborforce16plus = "DP03_0005",
                      # foreign born
                      countforeignborncitizen = "B05002_013",
                      countforeignbornundocumented = "B05002_021")) |> 
  select(!moe) |> 
  pivot_wider(names_from = variable,
              values_from = estimate)

predictors2022 <- predictors2022 |> 
  mutate(count18over = count18to24 + count24to34 + count35to44 + count45to64 + count65over,
         prop_less_than_hs = countlessthanhs / count18to24,
         prop_hs_grad = counthsgrad / count18to24,
         prop_some_college_associates = countsomecollegeassociates / count18to24,
         prop_bachelors_higher = countbachhigher / count18to24,
         prop_18_to_24 = count18to24 / totalpopulation,
         prop_65_years_older = count65over / totalpopulation,
         prop_white = countwhite / totalpopulation,
         prop_black = countblack / totalpopulation,
         prop_hispanic = counthispanic / totalpopulation,
         poverty_rate = countbelowpoverty / totalpopulation,
         unemployment_rate = countunemployedinlaborforce16plus / countlaborforce16plus,
         prop_foreign_born_citizen = countforeignborncitizen / totalpopulation,
         prop_undocumented = countforeignbornundocumented / totalpopulation,
         year = 2022) |> 
  rename(male_ratio_per_100_females = maleratioper100females,
         median_age = medianage,
         median_income = medianincome, 
         median_housing_costs = medianhousingcosts,
         total_population = totalpopulation,
         geoid = GEOID,
         name = NAME) |> 
  select(geoid,
         name,
         total_population,
         prop_less_than_hs,
         prop_hs_grad,
         prop_some_college_associates,
         prop_bachelors_higher,
         prop_18_to_24,
         prop_65_years_older,
         prop_white,
         prop_black,
         prop_hispanic,
         poverty_rate,
         unemployment_rate,
         male_ratio_per_100_females,
         median_age,
         median_income,
         gini,
         median_housing_costs,
         prop_foreign_born_citizen,
         prop_undocumented) |> 
  mutate(geoid = sub("^0+", "", geoid))

# merging county size predictors and calculating population density

predictors2022 <- left_join(x = predictors2022,
                      y = county_size,
                      by = "geoid") |> 
  mutate(land_area = as.numeric(land_area),
         population_density = total_population / land_area)

```

### Merge elections & predictor dataframes

```{r}

predictors2022 <- predictors2022 |>
  mutate(county_fips = geoid) |>
  select(-name, -geoid)
  
  
finaldata2024 <- left_join(x = elections2024_2020,
                      y = predictors2022,
                      by = "county_fips") 

```

# Set up testing environment using 2020 data

## Initial split

```{r}
set.seed(12071999)

modeling_sample <- initial_split(finaldata2020)

train <- training(modeling_sample)
test <- testing(modeling_sample)

```

## Exploratory analysis

```{r}

```

## V-fold cross-validation

```{r, warning=FALSE, message=FALSE}

train_folds <- vfold_cv(data = train, v = 10)

```

# Testing models using 2020 data

## Create a recipe

```{r}
recipe <-
  recipe(diff_current ~ diff_previous + prop_less_than_hs + prop_bachelors_higher + prop_18_to_24 + prop_65_years_older + prop_white + prop_black + prop_hispanic + poverty_rate + unemployment_rate + male_ratio_per_100_females + median_age + median_income + gini + median_housing_costs + prop_foreign_born_citizen + prop_undocumented + population_density,
         data = train) |>
  step_impute_knn(all_predictors()) |>
  step_corr(all_predictors()) |>
  step_log(median_income, median_housing_costs) |>
  step_interact(terms =  ~ prop_black*gini)

```

Justifications:

step_impute_knn(all_predictors())

step_corr(all_predictors())

step_log(median_income, median_housing_costs)

step_mutate(squared_median_age = median_age^2)

step_interact(terms =  ~ prop_black*gini): we expect that the relationship between income inequality and voting outcomes (margins) changes based on the proportion of a county that is black

## LASSO

```{r}
lasso_spec <- linear_reg(penalty = 0.1, mixture = 1) |>
    set_mode(mode = "regression") |>
    set_engine(engine = "glmnet")

lasso_wf <- workflow() |>
    add_recipe(recipe) |>
    add_model(lasso_spec)

lasso_resamples <- fit_resamples(
  lasso_wf,
  resamples = train_folds)

lasso_resamples |>
  collect_metrics()

```

## Decision Tree

```{r}
set.seed(20201020)

# creating a recipe

recipe_decision <- train |> 
  recipe(diff_current ~ diff_previous + prop_less_than_hs + prop_bachelors_higher + prop_18_to_24 + prop_65_years_older + prop_white + prop_black + prop_hispanic + poverty_rate + unemployment_rate + male_ratio_per_100_females + median_age + median_income + gini + median_housing_costs + prop_foreign_born_citizen + prop_undocumented + population_density) |> 
  step_impute_knn(all_predictors()) |>
  step_corr(all_predictors()) |>
  step_log(median_income, median_housing_costs, -all_outcomes()) |>
  step_interact(terms =  ~ prop_black*gini)

# creating a model

model_decision <- 
  decision_tree() |> 
  set_engine(engine = "rpart") |> 
  set_mode(mode = "regression")

# creating a workflow

workflow_decision <-
  workflow() |> 
  add_recipe(recipe_decision) |> 
  add_model(model_decision)

# fitting the data 

fit_decision <- workflow_decision |> 
  fit(data = finaldata2020)

# generate predictions

predictions_decision <- bind_cols(
  test,
  predict(object = fit_decision,
          new_data = test)
)

# evaluate the model

truth_decision <- predictions_decision |> 
  group_by(state_name) |> 
  summarize(sum_diff_current = sum(diff_current))

pred_decision <- predictions_decision |> 
  group_by(state_name) |> 
  summarize(sum_diff_prediction = sum(.pred))

finalmodel_decision <- truth_decision |> 
  left_join(pred_decision, by = "state_name") |> 
  mutate(difference_in_prediction = sum_diff_prediction - sum_diff_current,
         actual_winner = if_else(sum_diff_current < 0, "DEM", "GOP"),
         predicted_winner = if_else(sum_diff_prediction < 0, "DEM", "GOP"),
         correct_prediction = if_else(actual_winner == predicted_winner, 1, 0))

# loading electoral college

electoral_college <- read_csv("data/Electoral_College.csv") |> 
  select(!Abb_State) |> 
  rename(state_name = Full_State)

# merging decision tree final model with electoral college

finalmodel_decision <- finalmodel_decision |> 
  left_join(electoral_college, by = "state_name")

# calculating presidential race winners

finalmodel_decision |> 
  group_by(actual_winner) |> 
  summarize(sum_electoral_votes = sum(Electoral_College_Votes)) # actual winner was democrat with 316 electoral votes

finalmodel_decision |> 
  group_by(predicted_winner) |> 
  summarize(sum_electoral_votes = sum(Electoral_College_Votes)) # predicted winner was democrat with 274 electoral votes
  
```

## KNN

```{r}

# check to see if there are any na values

colSums(is.na(train)) > 0

folds_knn <- vfold_cv(data = train, v = 10, repeats = 5)

# construct the model

model_knn <- 
  nearest_neighbor(neighbors = tune()) |> 
  set_engine(engine = "kknn") |> 
  set_mode(mode = "regression")

# add the grid

grid_knn <- grid_regular(neighbors(range = c(1,99)),
                         levels = 10)

# same recipe

recipe_knn <- train |> 
  recipe(diff_current ~ diff_previous + prop_less_than_hs + prop_bachelors_higher + prop_18_to_24 + prop_65_years_older + prop_white + prop_black + prop_hispanic + poverty_rate + unemployment_rate + male_ratio_per_100_females + median_age + median_income + gini + median_housing_costs + prop_foreign_born_citizen + prop_undocumented + population_density) |> 
  step_impute_knn(all_predictors()) |>
  step_impute_knn(all_outcomes()) |>
  step_log(median_income, median_housing_costs, -all_outcomes()) |>
  step_interact(terms =  ~ prop_black*gini)

# create a workflow

workflow_knn <-
  workflow() |> 
  add_recipe(recipe = recipe_knn) |> 
  add_model(spec = model_knn)

res_knn <-
  workflow_knn |>  
  tune_grid(
    resample = folds_knn,
    grid = grid_knn,
    metrics = metric_set(rmse))

# collect rmse metrics

res_knn |> 
  collect_metrics()

# show best model

res_knn |> 
  show_best()

res_knn |> 
  autoplot()

# fit final knn model

final_wf_knn <-
  workflow_knn |> 
  finalize_workflow(select_best(res_knn))

final_fit_knn <-
  final_wf_knn |> 
  last_fit(modeling_sample)

final_fit_knn |> 
  collect_metrics
  
```


(Insert model here) has the lowest out of sample error rate

# Final model estimation on 2024 data
