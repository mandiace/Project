---
title: "Final Project"
author: "Mandi Acevedo, Kevin Velasco, Bela Walkin"
format: html
editor: visual
---

```{r, warning=FALSE, message=FALSE}
library(httr)
library(jsonlite)
library(modelr)
library(parsnip)
library(patchwork)
library(recipes)
library(scales)
library(sf)
library(stringr)
library(tidycensus)
library(tidymodels)
library(tidyr)
library(tidyverse)
library(tigris)

```

# Data cleaning & structuring

## 2020/2016 data

### Download 2020/2016 election results data

Data on 2016 and 2020 U.S. presidential elections results come from [this public GitHub repository](https://github.com/tonmcg/US_County_Level_Election_Results_08-24), which compiles results from reputable sources, including Politico and the New York Times. This data includes margins (out outcome variable).

```{r, warning=FALSE, message=FALSE}

elections2016  <- read_csv("data/2016_US_County_Level_Presidential_Results.csv")

elections2020  <- read_csv("data/2020_US_County_Level_Presidential_Results.csv")

```

### Merge 2020/2016 data into single file

```{r}

elections2020 <- elections2020 |>
  mutate(county_fips = as.character(str_remove(county_fips, "^0"))) 

elections2016 <- elections2016 |>
  mutate(county_fips = as.character(combined_fips)) |>
  select(-combined_fips, -diff) |> 
  mutate(diff = (votes_gop - votes_dem))
  

elections2020_2016 <- left_join(elections2020,
                                elections2016,
                                by = "county_fips")

colnames(elections2020_2016) <- gsub("\\.x$", "_current", colnames(elections2020_2016))
colnames(elections2020_2016) <- gsub("\\.y$", "_previous", colnames(elections2020_2016))

elections2020_2016 <- elections2020_2016 |>
  mutate(county_name = county_name_current) |>
  select(-county_name_previous, -county_name_current)

```

### Download county size data 

```{r, warning=FALSE, message=FALSE}

county_size <- read_csv("data/LND01.csv") |> 
  select(STCOU,
         LND010190D) |> 
  rename(geoid = STCOU,
         land_area = LND010190D) |> 
  mutate(geoid = sub("^0+", "", geoid))

# manually input data for Connecticut county-equivalents, as Census switched from using counties to Connecticut's Councils of Government divisions in 2022.

ct_county_eq_size <- data.frame(
  geoid = c(9110, 9120, 9130, 9140, 9150, 9160, 9170, 9180, 9190),
  land_area = c(1027.3, 140.2, 424.1, 412.8, 553.9, 786.6, 367.2, 598.1, 532.1)
) |> 
  mutate(geoid = as.character(geoid))

county_size <- county_size |> 
  bind_rows(ct_county_eq_size)

```

### Download county and state geospatial data

```{r}

counties_geospatial <-  counties(cb = TRUE) 

state_geospatial <- states(cb = TRUE)

```


### Download 2019 predictor data via API

We use 2019 predictor data rather than 2020 due to ACS availability. Many demographic variables (racial compositions, age distribution, etc.) do not change significantly year-on-year, so 2019 data should suffice for our purposes.

```{r, warning=FALSE, message=FALSE}

# download county demographic data

predictors2019 <- get_acs(dataset = "acs5",
                    year = 2019,
                    geography = "county",
                    variables = c(
                      # educational attainment
                      count18to24 = "S1501_C01_001",
                      count24to34 = "S1501_C01_016",
                      count35to44 = "S1501_C01_019",
                      count45to64 = "S1501_C01_022",
                      count65over = "S1501_C01_025",
                      countlessthanhs = "S1501_C01_002",
                      counthsgrad = "S1501_C01_003",
                      countsomecollegeassociates = "S1501_C01_004",
                      countbachhigher = "S1501_C01_005",
                      # total population
                      totalpopulation = "B01003_001",
                      # demographic information
                      maleratioper100females = "DP05_0004",
                      medianage = "DP05_0018",
                      countwhite = "DP05_0037",
                      countblack = "DP05_0038",
                      counthispanic = "DP05_0071",
                      # income
                      medianincome = "S1901_C01_012",
                      medianhhincome = "S1901_C02_012",
                      countbelowpoverty = "S1701_C02_001",
                      medianhousingcosts = "S2503_C01_024",
                      gini = "B19083_001",
                      # employment
                      countlaborforce16plus = "DP03_0002",
                      countunemployedinlaborforce16plus = "DP03_0005",
                      # foreign born
                      countforeignborncitizen = "B05002_013",
                      countforeignbornundocumented = "B05002_021")) |> 
  select(!moe) |> 
  pivot_wider(names_from = variable,
              values_from = estimate)
                      
predictors2019 <- predictors2019 |> 
  mutate(count18over = count18to24 + count24to34 + count35to44 + count45to64 + count65over,
         prop_less_than_hs = countlessthanhs / count18to24,
         prop_hs_grad = counthsgrad / count18to24,
         prop_some_college_associates = countsomecollegeassociates / count18to24,
         prop_bachelors_higher = countbachhigher / count18to24,
         prop_18_to_24 = count18to24 / totalpopulation,
         prop_65_years_older = count65over / totalpopulation,
         prop_white = countwhite / totalpopulation,
         prop_black = countblack / totalpopulation,
         prop_hispanic = counthispanic / totalpopulation,
         poverty_rate = countbelowpoverty / totalpopulation,
         unemployment_rate = countunemployedinlaborforce16plus / countlaborforce16plus,
         prop_foreign_born_citizen = countforeignborncitizen / totalpopulation,
         prop_undocumented = countforeignbornundocumented / totalpopulation,
         year = 2019) |> 
  rename(male_ratio_per_100_females = maleratioper100females,
         median_age = medianage,
         median_income = medianincome, 
         median_housing_costs = medianhousingcosts,
         total_population = totalpopulation,
         geoid = GEOID,
         name = NAME) |> 
  select(geoid,
         name,
         total_population,
         prop_less_than_hs,
         prop_hs_grad,
         prop_some_college_associates,
         prop_bachelors_higher,
         prop_18_to_24,
         prop_65_years_older,
         prop_white,
         prop_black,
         prop_hispanic,
         poverty_rate,
         unemployment_rate,
         male_ratio_per_100_females,
         median_age,
         median_income,
         gini,
         median_housing_costs,
         prop_foreign_born_citizen,
         prop_undocumented) |> 
  mutate(geoid = sub("^0+", "", geoid))

# merging county size predictors and calculating population density

predictors2019 <- left_join(x = predictors2019,
                      y = county_size,
                      by = "geoid") |> 
  mutate(land_area = as.numeric(land_area),
         population_density = total_population / land_area)

```

### Merge elections & predictor dataframes

```{r}

predictors2019 <- predictors2019 |>
  mutate(county_fips = geoid) |>
  select(-name, -geoid)
  
  
finaldata2020 <- left_join(x = elections2020_2016,
                      y = predictors2019,
                      by = "county_fips")

```

### Rectify missing data

The only observations in our dataset with missing variables are observations in the state of Alaska. The elections dataset divides Alaska into its 40 state-level congressional districts, but our predictor dataset divides Alaska by its 30 boroughs and census areas (Alaskan county-equivalents).

We are thus removing all Alaskan observations from our dataset, limiting the external validity of our model.

There is also a single observation in South Dakota that is missing data. We drop this variable rather than impute for the sake of time, since a single observation should not significantly impact results.

```{r}

finaldata2020 |>
  filter(if_any(everything(), is.na))

finaldata2020 <- finaldata2020 |>
  filter(state_name != "Alaska") |>
  filter(county_fips != 46102)

finaldata2020 |>
  filter(if_any(everything(), is.na)) ## confirmed no missing data

```
```{r}
## exploring 0 for predictors


```

## 2024/2020 data

### Download 2024 election results data

```{r, warning=FALSE, message=FALSE}

elections2024  <- read_csv("data/2024_US_County_Level_Presidential_Results.csv")

```

### Rolling up DC elections data into a single row

DC data is presented by ward in the elections dataset, but not the 2022 predictors dataset.

```{r, warning=FALSE, message=FALSE}

dc_data <- elections2024 |>
  filter(state_name == "District of Columbia") |>
  mutate(
    weighted_percent_votes_gop = per_gop * total_votes,
    weighted_percent_votes_dem = per_dem * total_votes,
    weighted_percent_points_diff = per_point_diff * total_votes
  ) |> 
  summarize(
    county_fips = 11001,
    votes_gop = sum(votes_gop),
    votes_dem = sum(votes_dem),
    total_votes = sum(total_votes),
    diff = sum(diff),
    per_gop = sum(weighted_percent_votes_gop) / sum(total_votes),
    per_dem = sum(weighted_percent_votes_dem) / sum(total_votes),
    per_point_diff = sum(weighted_percent_points_diff) / sum(total_votes),
    state_name = "District of Columbia",
    county_name = "District of Columbia"
  ) |> 
  mutate(county_fips = as.character(county_fips))

```

### Merge 2024/2020 elections data into single file

```{r, warning=FALSE, message=FALSE}

elections2024 <- elections2024 |> 
  filter(!county_fips %in% c(11001, 11002, 11003, 11004, 11005, 11006, 11007, 11008)) |> # data inputted manually from census burea information
  bind_rows(dc_data)

# rest of merge

elections2024 <- elections2024 |>
  mutate(county_fips = as.character(str_remove(county_fips, "^0"))) 

elections2024_2020 <- left_join(elections2024,
                                elections2020,
                                by = "county_fips")

colnames(elections2024_2020) <- gsub("\\.x$", "_current", colnames(elections2024_2020))
colnames(elections2024_2020) <- gsub("\\.y$", "_previous", colnames(elections2024_2020))

elections2024_2020 <- elections2024_2020 |>
  mutate(county_name = county_name_current) |>
  select(-county_name_previous, -county_name_current)

elections2024_2020 <- elections2024_2020 |>
  mutate(state_name = state_name_current) |>
  select(-state_name_previous, -state_name_current)
```

### Download 2022 predictor data via API

Similar to our 2020 dataset, we use 2022 predictor data rather than 2024 due to ACS availability. Many demographic variables (racial compositions, age distribution, etc.) do not change significantly year-on-year, so 2024 data should suffice for our purposes.

```{r, warning=FALSE, message=FALSE}

# download county demographic data

predictors2022 <- get_acs(dataset = "acs5",
                    year = 2022,
                    geography = "county",
                    variables = c(
                      # educational attainment
                      count18to24 = "S1501_C01_001",
                      count24to34 = "S1501_C01_016",
                      count35to44 = "S1501_C01_019",
                      count45to64 = "S1501_C01_022",
                      count65over = "S1501_C01_025",
                      countlessthanhs = "S1501_C01_002",
                      counthsgrad = "S1501_C01_003",
                      countsomecollegeassociates = "S1501_C01_004",
                      countbachhigher = "S1501_C01_005",
                      # total population
                      totalpopulation = "B01003_001",
                      # demographic information
                      maleratioper100females = "DP05_0004",
                      medianage = "DP05_0018",
                      countwhite = "DP05_0037",
                      countblack = "DP05_0038",
                      counthispanic = "DP05_0071",
                      # income
                      medianincome = "S1901_C01_012",
                      medianhhincome = "S1901_C02_012",
                      countbelowpoverty = "S1701_C02_001",
                      medianhousingcosts = "S2503_C01_024",
                      gini = "B19083_001",
                      # employment
                      countlaborforce16plus = "DP03_0002",
                      countunemployedinlaborforce16plus = "DP03_0005",
                      # foreign born
                      countforeignborncitizen = "B05002_013",
                      countforeignbornundocumented = "B05002_021")) |> 
  select(!moe) |> 
  pivot_wider(names_from = variable,
              values_from = estimate)

predictors2022 <- predictors2022 |> 
  mutate(count18over = count18to24 + count24to34 + count35to44 + count45to64 + count65over,
         prop_less_than_hs = countlessthanhs / count18to24,
         prop_hs_grad = counthsgrad / count18to24,
         prop_some_college_associates = countsomecollegeassociates / count18to24,
         prop_bachelors_higher = countbachhigher / count18to24,
         prop_18_to_24 = count18to24 / totalpopulation,
         prop_65_years_older = count65over / totalpopulation,
         prop_white = countwhite / totalpopulation,
         prop_black = countblack / totalpopulation,
         prop_hispanic = counthispanic / totalpopulation,
         poverty_rate = countbelowpoverty / totalpopulation,
         unemployment_rate = countunemployedinlaborforce16plus / countlaborforce16plus,
         prop_foreign_born_citizen = countforeignborncitizen / totalpopulation,
         prop_undocumented = countforeignbornundocumented / totalpopulation,
         year = 2022) |> 
  rename(male_ratio_per_100_females = maleratioper100females,
         median_age = medianage,
         median_income = medianincome, 
         median_housing_costs = medianhousingcosts,
         total_population = totalpopulation,
         geoid = GEOID,
         name = NAME) |> 
  select(geoid,
         name,
         total_population,
         prop_less_than_hs,
         prop_hs_grad,
         prop_some_college_associates,
         prop_bachelors_higher,
         prop_18_to_24,
         prop_65_years_older,
         prop_white,
         prop_black,
         prop_hispanic,
         poverty_rate,
         unemployment_rate,
         male_ratio_per_100_females,
         median_age,
         median_income,
         gini,
         median_housing_costs,
         prop_foreign_born_citizen,
         prop_undocumented) |> 
  mutate(geoid = sub("^0+", "", geoid))

# merging county size predictors and calculating population density

predictors2022 <- left_join(x = predictors2022,
                      y = county_size,
                      by = "geoid") |> 
  mutate(land_area = as.numeric(land_area),
         population_density = total_population / land_area)

```

Why did we choose these predictors? 

According to a study conducted by Kulachi et al. (2023), voting behavior is very dynamic. People's voting patterns depend on a culmination of numerous factors. Some factors shown to impact voting behavior that are included in this analysis are economic, gender, ethnicity and race, and age variables. Thus, we pulled predictors within these groupings. Other factors that have been shown to influence voting behaviors, like health care experiences, media influences, are difficult to estimate at an individual level. Thus, these are much more difficult to estimate at a county level. Due to the complexities in estimating these variables and limited data access, we do not include these variables in our analysis. 

### Merge elections & predictor dataframes

```{r, warning=FALSE, message=FALSE}

predictors2022 <- predictors2022 |>
  mutate(county_fips = geoid) |>
  select(-name, -geoid)
  
  
finaldata2024 <- left_join(x = elections2024_2020,
                      y = predictors2022,
                      by = "county_fips") 

```

### Rectify missing data

Again, we remove Alaskan observations and the singular South Dakota observation, for the same reasons we did in the 2020 data.

We also drop Kenedy and Loving Counties, both in Texas, as they are two of the smallest counties in the U.S. with a permanent population. Observations are missing median income and housing cost data.

Beginning in 2022, Connecticut switched from using counties to using Councils of Government for statistical reporting purposes. The new county-equivalents do not match the previous boundaries of counties. Connecticut is thus missing 2020 elections results data, which will be rectified via imputation in our recipe.

```{r}

finaldata2024 |>
  filter(if_any(everything(), is.na))

finaldata2024 <- finaldata2024 |>
  filter(state_name != "Alaska") |>
  filter(county_fips != 46102 &
           county_fips != 48261 &
           county_fips != 48301)

finaldata2024 |>
  filter(if_any(everything(), is.na)) ## confirmed no missing data outside of Connecticut 2020 voting data

```


```{r}
## missing data 


### education data 

highschool <- finaldata2020 |>
  filter(prop_less_than_hs == 0) 

highschool_unique <- unique(highschool[, c("state_name", "county_name")])

# Counties missing high school data
print(highschool_unique)

## Checking for missing grad highs school data

highschool_g <- finaldata2020 |>
  filter(prop_less_than_hs == 0) 

highschool_unique_g <- unique(highschool_g[, c("state_name", "county_name")])
print(highschool_unique_g)

#### consistent across education groups 

### land area

finaldata2020 |>
  summarize(min_land_area = min(land_area)) 

land_missing <- finaldata2020 |>
  filter(land_area == 0)

land_missing_unique <- unique(land_missing[, c("state_name", "county_name")])
print(land_missing_unique)

### population 

finaldata2020 |>
  summarize(min_population = min(total_population)) # total population all good

### age 

finaldata2020 |>
  summarize(min_age_18 = min(prop_18_to_24))

finaldata2020 |>
  summarize(min_pro_65 = min(prop_65_years_older)) # age looks fine


###  race data, need to check but could be correct
finaldata2020 |>
  summarize(min_prop_white = min(prop_white))

finaldata2020 |>
  summarize(min_prop_black = min(prop_black)) ## this is 0. Is this possible?? 

black_zero <- finaldata2020 |>
  filter(prop_black == 0)

black_zero_unique <- unique(black_zero[, c("state_name", "county_name")])
print(black_zero_unique)

finaldata2020 |>
  summarize(min_prop_hisp = min(prop_hispanic)) 

hispanic_zero <- finaldata2020 |>
  filter(prop_hispanic == 0)

hispanic_zero_unqiue <- unique(hispanic_zero[, c("state_name", "county_name")])
print(hispanic_zero_unqiue)

### unemployment 
finaldata2020 |>
  summarize(min_unemp = min(unemployment_rate)) # has 0

### male 
finaldata2020 |>
  summarise(minmal = min(male_ratio_per_100_females)) # all good

### median



```

# Set up testing environment using 2020 data

## Initial split

```{r}

set.seed(12071999)

modeling_sample <- initial_split(finaldata2020)

train <- training(modeling_sample)
test <- testing(modeling_sample)

```

## Exploratory analysis

```{r, warning=FALSE, message=FALSE}

theme_set(theme_minimal())

elections2020 |>
  mutate(winner = ifelse(diff < 0, "dem", "rep")) |> 
  ggplot(aes(x = diff, fill = winner)) +
  geom_histogram(binwidth = 5000, color = "black") +
  scale_x_continuous(labels = scales::number_format(scale = 1), limits = c(-200000, 200000)) +
  scale_fill_manual(values = c("dem" = "blue", "rep" = "red")) +
  labs(title = "Count of Party Wins by County Margin in 2020")

finaldata2020 |>
  mutate(pop_size_decile = ntile(total_population, 10)) |>
  mutate(winner = ifelse(diff_current < 0, "dem", "rep")) |>
  group_by(pop_size_decile) |>
  summarise("dem wins" = sum(winner == "dem"),
            "rep wins" = sum(winner == "rep"),
            "share dem wins" = sum(winner == "dem") / n())

```

Republicans won more counties than Democrats in the 2020 presidential election, but the Democratic tail of the distribution is much longer, indicating that large margins happened more often in counties that Democrats won than in counties that Republicans won. We know that a Republican candidate did not win in 2020. This implies that while the Republican candidate won more counties overall, Democrats disproportionately win counties with large populations. This is demonstrated in our table. In 2020, the Republican candidate won the significant majority of all counties with a below-90th percentile population size. However, the Democratic candidate won about 68% the largest 10% of counties in the nation.

This plot also demonstrates why we decided not to model a binary outcome variable capturing whether a Republican won in each county, as such a model will be biased towards Republicans and is not useful in informing national-level winners. Instead, we chose to use margins as our outcome variable, which captures the same information as a binary winner variable while also potentially proving more useful for national-level predictions.
```{r}
# Exploring spread of values in margins variable in 2020 election

finaldata2020 |>
  summarize(max_diff = max(diff_current),
            min_diff = min(diff_current),
            mean_diff = mean(diff_current),
            sd_diff = sd(diff_current))


```
The maximum difference indicates a republican winner and the minimum difference is negative. This makes sense. Looking at the maximum and minimum values, the minimum value has a higher magnitude than the maximum value. This means that there is at least one occurence where democrats win by an extremely high margin, compared to the how much republicans win. 

```{r}
# Exploring these margin outliers for the democrats in 2020 presidential election
finaldata2020 |>
  summarize(outlier_dem = sum(diff_current < -119005))

finaldata2020 |>
  filter(diff_current < -119005) |>
  summarize(min_dem_outlier = min(diff_current),
            max_dem_outlier = max(diff_current), 
            mean_dem_outlier = mean(diff_current), 
            sd_dem_outleir = sd(diff_current))
```
This shows that we have 53 counties that are above the highest margin for a republican win. Looking at the standard deviation presented by these values, it shows that these values vary greatly in their magnitude. This could mean that we should be concerned about outliers for when a democrat wins in particular, as they won by higher margins in the 2020 election. 

```{r}
# Is outlier situation the same for the 2016 election


finaldata2020 |>
  summarize(max_diff_past = max(diff_previous),
            min_diff_past = min(diff_previous),
            mean_diff_past = mean(diff_previous),
            sd_diff_past = sd(diff_previous))
```
For the 2016 election, this may be the case as well, the magnitude for counties where a democrat won is much higher than the republican win. 

```{r}
# Exploring these margin outliers for the democrats in 2020 presidential election

finaldata2020 |>
  summarize(outlier_dem = sum(diff_previous < -104444))

finaldata2020 |>
  filter(diff_previous < -104444) |>
  summarize(min_dem_outlier = min(diff_previous),
            max_dem_outlier = max(diff_previous), 
            mean_dem_outlier = mean(diff_previous), 
            sd_dem_outleir = sd(diff_previous))

```

In the 2016 election, 45 values may be strong outliers in the analysis. This is relatively close to the number of outliers in the 2020 presidential election. Similarly, the standard deviation is relatively high as well. This may mean that the values are not close together, varying greatly. However, the mean is decently close to the minimum value, telling us that the outlier with the largest magnitude may be pulling these values upwards, and the rest of the outliers are closer to the -104746 value. Since the number of outliers is decently similar between the 2016 and 2020 presidential election (53 and 45), this may not be of strong concern. These outliers may also be of less concern since they make up such a small portion of the data set. The values we would be concerned about make up about 1.7%. 

```{r}
#What counties make up these outliers in both the 2016 and 2020 elections? 

outliers <- finaldata2020 |>
  filter(diff_current < -119005 | diff_previous < -104444)

print(table(outliers$state_name))

```
As expected, California repeats the most in the outliers for democrat wins. Interestingly, some swing states show up in this. Since so few show up in this analysis, and many in places we would expect a democrat win, this may not be of great concern. However, it is interesting to note. Possibly, state could be interesting predictor for a place like California. 


```{r, warning=FALSE, message=FALSE}
#Education distribution by County Winner 


finaldata2020 |>
  select(state_name, prop_less_than_hs, prop_hs_grad, prop_some_college_associates, prop_bachelors_higher, diff_current) |>
  mutate(winner = ifelse(diff_current < 0, "Dem", "Rep")) |> 
  group_by(winner) |> 
  pivot_longer(cols = c(prop_less_than_hs, prop_hs_grad, prop_some_college_associates, prop_bachelors_higher),
               names_to = "education_level", values_to = "proportion") |>
  mutate(proportion_two = proportion / sum(proportion) * 100) |>
ggplot(aes(x = winner, y = proportion_two, fill = education_level)) +
  geom_bar(stat = "identity") +
  labs(title = "Education Distribution by County Winner in 2020", y = "Proportion (%)", x = "Winner") +
  scale_y_continuous(labels = scales::percent) +  
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(axis.text.y = element_blank(),
        axis.title.y = element_blank())

  
```
This graph suggests that counties who voted Democratic in 2020 had a higher number of residents with some college education. We capture educational attainment in the model using a number of predictors, as the leftward political shift of college-educated individuals in recent decades has made educational patterns a potentially useful indicator for voting outcomes. Since education spread, at large, is s

```{r}
# Is there a relationship between education levels and who wins in the presidential election? 

finaldata2020 |>
  filter(diff_current > -100000) |> # filtering out the two outliers to better see data spread
  ggplot() +
  geom_point(aes(x = prop_less_than_hs, y = diff_current)) +
  geom_smooth(mapping = aes(x = prop_less_than_hs,
                            y = diff_current),
              method = "lm",
              se = FALSE,
              color = "grey",
              linetype = "dashed") + 
  labs(title = "Associaion between less than high school and margin win")

finaldata2020 |>
  filter(diff_current > -100000) |> # filtering out the two outliers to better see data spread
  ggplot() +
  geom_point(aes(x = prop_hs_grad, y = diff_current)) +
  geom_smooth(mapping = aes(x = prop_hs_grad,
                            y = diff_current),
              method = "lm",
              se = FALSE,
              color = "grey",
              linetype = "dashed") + 
  labs(title = "Associaion between high school grad and margin win")

finaldata2020 |>
  filter(diff_current > -100000) |> # filtering out the two outliers to better see data spread
  ggplot() +
  geom_point(aes(x = prop_some_college_associates, y = diff_current)) +
  geom_smooth(mapping = aes(x = prop_some_college_associates,
                            y = diff_current),
              method = "lm",
              se = FALSE,
              color = "grey",
              linetype = "dashed") + 
  labs(title = "Associaion between some college or associates and margin win")

finaldata2020 |>
  filter(diff_current > -100000) |> # filtering out the two outliers to better see data spread
  ggplot() +
  geom_point(aes(x = prop_bachelors_higher, y = diff_current)) +
  geom_smooth(mapping = aes(x = prop_bachelors_higher,
                            y = diff_current),
              method = "lm",
              se = FALSE,
              color = "grey",
              linetype = "dashed") + 
  labs(title = "Associaion between Bachelors or higher and margin win")


```
The proportion of people with bachelors degree or higher and its association with the margin winner is the strongest out of all education varibles, since it is the steepest line. Additionally, this association is most interesting, as it is also negative. Some college associates is also negative, although not as steep. Less than high school and margins winner is the flattest, telling us there is little relationship between these two, although it is positively associated. High school grad and margin have a moderately psotive relationship. This could mean that two key predictors for education in this model may be bachelors or higher and high school grad. 

```{r, warning=FALSE, message=FALSE}

# Choosing Population Variables
finaldata2020 |>
  ggplot() +
  geom_point(aes(x = total_population,
                 y = land_area),
             alpha = 0.1,
             color = "pink") + 
  geom_smooth(mapping = aes(x = total_population,
                            y = land_area),
              method = "lm",
              se = FALSE,
              color = "black",
              linetype = "dashed") +
  labs(title = "Land Area and Total Population")

# 2020
finaldata2020 |>
  ggplot() +
  geom_point(aes(x = population_density, 
                 y = diff_current), 
           alpha = 0.6, 
           color = "pink") + 
  geom_smooth(mapping = aes(x = population_density,
                            y = diff_current),
              method = "lm",
              se = FALSE,
              color = "grey",
              linetype = "dashed") + 
  labs(
    title = "Population Density and Margin in 2020",
    x = "Population Density",
    y = "Margin") 



```
As population increases, the land area increases, on average. This graph does show though, that certain areas have a higher population and lower land mass. These are urban areas. This graph demonstrates the reason why we chose to use population density as a predictor rather than total population or land area alone. Those measurements alone do not precisely capture all facets of the living situation certain counties are in. 

In looking at the association between the association population density and the election margin, it has a negative association. That is, an increase in the population density is associated with a decrease in the margin. This means that an increase in population density is associated with a democrat winning in the 2020 election. 



```{r, warning=FALSE, message=FALSE}

# Choosing Economic Variables
finaldata2020 |>
  ggplot() +
  geom_point(aes(x = unemployment_rate,
                 y = diff_current,
                 color = poverty_rate >= 0.2),
             alpha = 0.2) + 
  geom_smooth(mapping = aes(x = unemployment_rate,
                            y = diff_current),
              method = "lm",
              se = FALSE,
              color = "black",
              linetype = "dashed") +
  labs(title = "Unemployment Rate and Margin") +
  scale_y_continuous(labels = scales::number_format(scale = 1), limits = c(-200000, 200000)) +
  scale_color_manual(values = c("TRUE" = "red", "FALSE" = "green")) 

```
This graph shows that  lower unemployment rates are associated with republican wins (Republican win = positive margin). Interestingly, higher unemployment rates are not necessarily associated with negitive margins, or democratic party wins. The summary line shows that while the association between the party win and unemployment rates is negative (an increase in unemployment rate is associated with a decrease in margins), it is barely negative. This means the association between who wins a presidential election and unemployment rate might not be helpful. As expected though, counties with higher unemployment rates are more likely to fall below the poverty line, which we defined as 20% (based on the USDA, Economic Research Serviceâ€™s (ERS) Poverty Area Measures). It is also interesting to note that places with a high poverty rate seem to have a smaller margin, and do not necessarily fall into a democrat winner or a republican winner. That being said, more counties with a high poverty rate do vote have a democrat win in the presidential election.

```{r}
# Exploring povrty rate more

finaldata2020 |>
  ggplot() +
  geom_point(aes(x = unemployment_rate,
                 y = diff_current)) +
  geom_smooth(mapping = aes(x = unemployment_rate, 
                            y = diff_current),
               method = "lm",
              se = FALSE,
              color = "grey",
              linetype = "dashed") +
  geom_vline(xintercept = 0.1, linetype = "dotted", color = "blue") +
  annotate("text", x = 0.11, y = max(finaldata2020$diff_previous, na.rm = TRUE), 
           label = "High Unemployment Rate, 10%", color = "blue", hjust = 0) +
  labs(title = "Unemployment rate and Margins in 2020 election")
  

finaldata2020 |>
  filter(diff_current > -100000) |> # filtering out the two outliers to better see data spread
  ggplot() +
  geom_point(aes(x = unemployment_rate,
                 y = diff_current)) +
  geom_smooth(mapping = aes(x = unemployment_rate, 
                            y = diff_current),
               method = "lm",
              se = FALSE,
              color = "grey",
              linetype = "dashed") +
  geom_vline(xintercept = 0.1, linetype = "dotted", color = "blue") +
  annotate("text", x = 0.11, y = max(finaldata2020$diff_previous, na.rm = TRUE), 
           label = "High Unemployment Rate, 10%", color = "blue", hjust = 0) +
  labs(title = "Unemployment rate and Margins in 2020 election removing outliers")
  




  
```
In these graphs, we checked to see how unemployment rate might be associated with the margins variable in both the 2020, both with and without the outliers in the margins variable. In both graphs, there is little to no association between the two. The vertical line represents where high unemployment rate is, 10% (based on the Organization for Economic Co-operation and Development 2013 factbook). It does not appear that having a high unemployment rate  would change the non-relationship between unemployment rate and margins variable. These graphs demonstrate that unemployment rate may not be a strong predictor. Although it looks more counties with a high unemployment rate favored the democratic party, it does not appear to be more by a significnat amount. 

```{r, warning=FALSE, message=FALSE}

# Choosing inequality estimators
finaldata2020 |>
  mutate(winner = ifelse(diff_current < 0, "Dem", "Rep")) |> 
  group_by(winner) |> 
  ggplot() +
  geom_point(aes(x = poverty_rate, y = gini, color = winner), 
             alpha = 0.2) + 
  geom_smooth(mapping = aes(x = poverty_rate, 
                            y = gini, 
                            group = winner, 
                            color = winner),
              method = "lm", 
              se = FALSE, 
              linetype = "dashed") + 
  scale_color_manual(values = c("Dem" = "blue", "Rep" = "red")) +
  labs(title = "Poverty Rate vs. Gini Index by Winner",
       x = "Poverty Rate",
       y = "Gini Index")


  
```
This graph shows that an increase in poverty rate is associated with an increase in the gini index, or income inequality, regardless of what party won in the presidential election. What is interesting is that for counties where a republican candidate won, the summary line starts at a lower point in the graph and ends higher. That is, the republican line is steeper than the democratic line. This could mean that for republican-winning counties, the relationship between poverty rate and gini index is more negatively associated then democrat winning counties. This graph looks like democrat winning counties fall higher on the gini index and poverty rate. Below, we dive into this relationship further. 

```{r}
# Exploring gini index and poverty rate relationship with winning party

finaldata2020 |>
  ggplot() +
  geom_point(aes(x = poverty_rate, 
                 y = diff_current)) + 
  geom_smooth(mapping = aes(x = poverty_rate, 
                            y = diff_current)) +
  labs(title = "Association between Poverty Rate and Margins Winner in 2020")


finaldata2020 |>
  ggplot() +
  geom_point(aes(x = gini, 
                 y = diff_current)) + 
  geom_smooth(mapping = aes(x = poverty_rate, 
                            y = diff_current)) +
  labs(title = "Association between Gini Index and Margins Winner in 2020")


```

Neither poverty rate or gini index on their own seem to be a significant predictor of who won the county in the 2020 presidential election. Since a previous graph shows that relationship between the gini index and poverty rate seems to have a more significant effect in counties where republicans won, this could mean an interaction of the gini and poverty variables may be a helpful predictor. 

```{r}
# Age 

finaldata2020 |>
  

# Distribution
finaldata2020 |>
  select(state_name, prop_18_to_24, prop_65_years_older, diff_current) |>
  mutate(winner = ifelse(diff_current < 0, "Dem", "Rep")) |> 
  group_by(winner) |> 
  mutate(dem_18 = mean() )
  pivot_longer(cols = c(prop_18_to_24, prop_18_to_24, prop_other),
               names_to = "education_level", values_to = "proportion") |>
ggplot(aes(x = winner, y = proportion, fill = education_level)) +
  geom_bar(stat = "identity") +
  labs(title = "Education Distribution by County Winner in 2020", y = "Proportion (%)", x = "Winner") +
  scale_y_continuous(labels = scales::percent) +  
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(axis.text.y = element_blank(),
        axis.title.y = element_blank())

  
  
finaldata2020 |>
  select(state_name, prop_18_to_24, prop_65_years_older, diff_current) |>
  mutate(winner = ifelse(diff_current < 0, "Dem", "Rep"),
         prop_other = 1 - (prop_18_to_24 + prop_65_years_older)) |> 
  group_by(winner) |> 
  summarize(
    avg_18_to_24 = mean(prop_18_to_24, na.rm = TRUE) * 100,
    avg_65_years_older = mean(prop_65_years_older, na.rm = TRUE) * 100,
    avg_other = mean(prop_other, na.rm = TRUE) * 100,
    .groups = "drop"
  ) |> 
  pivot_longer(
    cols = c(avg_18_to_24, avg_65_years_older, avg_other),
    names_to = "age_group", 
    values_to = "avg_proportion"
  ) |> 
  ggplot(aes(x = winner, y = avg_proportion, fill = age_group)) +
  geom_bar(stat = "identity") +
  labs(
    title = "Average Age Group Proportions by County Winner in 2020",
    y = "Average Proportion (%)",
    x = "Winner"
  ) +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) +  
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```
As expected, the age group that seems to be different between counties where a democrat won versus a republican is the 18 to 24 category. It appears that younger people vote more for the democratic candidate than the republican candidate. As expected, the republican counties had a higher share of the older age population voting for them. This falls in line with our intuition and tells us its propbably important to include both in our model.   

NEED TO JUSTIFY SPECIFIC RACE VARIABLES, AGE, FOREIGN BORN, UNDOCUMENTED, MEDIAN HOUSING COST

## V-fold cross-validation

```{r, warning=FALSE, message=FALSE}

train_folds <- vfold_cv(data = train, v = 10)

```

# Testing models using 2020 data

## Create a recipe

```{r, warning=FALSE, message=FALSE}

recipe <-
  recipe(diff_current ~ diff_previous + prop_less_than_hs + prop_bachelors_higher + prop_18_to_24 + prop_65_years_older + prop_white + prop_black + prop_hispanic + poverty_rate + unemployment_rate + male_ratio_per_100_females + median_age + median_income + gini + median_housing_costs + prop_foreign_born_citizen + prop_undocumented + population_density + total_population,
         data = train) |>
  step_impute_knn(all_predictors()) |>
  step_corr(all_predictors()) |>
  step_log(median_income, median_housing_costs) |>
  step_interact(terms =  ~ prop_black*gini)

```

Justifications:

step_impute_knn(all_predictors())

step_corr(all_predictors())

step_log(median_income, median_housing_costs)

step_mutate(squared_median_age = median_age\^2)

step_interact(terms = \~ prop_black\*gini): we expect that the relationship between income inequality and voting outcomes (margins) changes based on the proportion of a county that is black

## LASSO

```{r, warning=FALSE, message=FALSE}

set.seed(12071999)

lasso_spec <- linear_reg(penalty = tune(), 
                         mixture = 1) |>
    set_mode(mode = "regression") |>
    set_engine(engine = "glmnet")

lasso_wf <- workflow() |>
    add_recipe(recipe) |>
    add_model(lasso_spec)

lasso_grid <- grid_regular(
  penalty(range = c(0, 15)),
  levels = 5)

lasso_resamples <- lasso_wf |>
  tune_grid(resamples = train_folds,
            grod = lasso_grid)

lasso_resamples |>
  collect_metrics(type = "wide")

show_best(lasso_resamples)

```

## Decision Tree

```{r, warning=FALSE, message=FALSE}

set.seed(12071999)

# creating a recipe

recipe_decision <- train |> 
  recipe(diff_current ~ diff_previous + prop_less_than_hs + prop_bachelors_higher + prop_18_to_24 + prop_65_years_older + prop_white + prop_black + prop_hispanic + poverty_rate + unemployment_rate + male_ratio_per_100_females + median_age + median_income + gini + median_housing_costs + prop_foreign_born_citizen + prop_undocumented + population_density) |> 
  step_impute_knn(all_predictors()) |>
  step_corr(all_predictors()) |>
  step_log(median_income, median_housing_costs, -all_outcomes()) |>
  step_interact(terms =  ~ prop_black*gini)

# creating a model

model_decision <- 
  decision_tree() |> 
  set_engine(engine = "rpart") |> 
  set_mode(mode = "regression")

# creating a workflow

workflow_decision <-
  workflow() |> 
  add_recipe(recipe_decision) |> 
  add_model(model_decision)

# fitting the data 

fit_decision <- workflow_decision |> 
  fit(data = finaldata2020)

# generate predictions

predictions_decision <- bind_cols(
  test,
  predict(object = fit_decision,
          new_data = test)
)

# evaluate the model

truth_decision <- predictions_decision |> 
  group_by(state_name) |> 
  summarize(sum_diff_current = sum(diff_current))

pred_decision <- predictions_decision |> 
  group_by(state_name) |> 
  summarize(sum_diff_prediction = sum(.pred))

finalmodel_decision <- truth_decision |> 
  left_join(pred_decision, by = "state_name") |> 
  mutate(difference_in_prediction = sum_diff_prediction - sum_diff_current,
         actual_winner = if_else(sum_diff_current < 0, "DEM", "GOP"),
         predicted_winner = if_else(sum_diff_prediction < 0, "DEM", "GOP"),
         correct_prediction = if_else(actual_winner == predicted_winner, 1, 0))

# loading electoral college

electoral_college <- read_csv("data/Electoral_College.csv") |> 
  select(!Abb_State) |> 
  rename(state_name = Full_State)

# merging decision tree final model with electoral college

finalmodel_decision <- finalmodel_decision |> 
  left_join(electoral_college, by = "state_name")

# calculating presidential race winners

finalmodel_decision |> 
  group_by(actual_winner) |> 
  summarize(sum_electoral_votes = sum(Electoral_College_Votes)) # actual winner was democrat with 316 electoral votes

finalmodel_decision |> 
  group_by(predicted_winner) |> 
  summarize(sum_electoral_votes = sum(Electoral_College_Votes)) # predicted winner was democrat with 274 electoral votes

# constructing electoral map by county


  
```

## KNN

```{r, warning=FALSE, message=FALSE}

set.seed(12071999)

# check to see if there are any na values

colSums(is.na(train)) > 0

folds_knn <- vfold_cv(data = train, v = 10, repeats = 5)

# construct the model

model_knn <- 
  nearest_neighbor(neighbors = tune()) |> 
  set_engine(engine = "kknn") |> 
  set_mode(mode = "regression")

# add the grid

grid_knn <- grid_regular(neighbors(range = c(1,99)),
                         levels = 10)

# same recipe

recipe_knn <- train |> 
  recipe(diff_current ~ diff_previous + prop_less_than_hs + prop_bachelors_higher + prop_18_to_24 + prop_65_years_older + prop_white + prop_black + prop_hispanic + poverty_rate + unemployment_rate + male_ratio_per_100_females + median_age + median_income + gini + median_housing_costs + prop_foreign_born_citizen + prop_undocumented + population_density) |> 
  step_impute_knn(all_predictors()) |>
  step_impute_knn(all_outcomes()) |>
  step_log(median_income, median_housing_costs, -all_outcomes()) |>
  step_interact(terms =  ~ prop_black*gini)

# create a workflow

workflow_knn <-
  workflow() |> 
  add_recipe(recipe = recipe_knn) |> 
  add_model(spec = model_knn)

res_knn <-
  workflow_knn |>  
  tune_grid(
    resample = folds_knn,
    grid = grid_knn,
    metrics = metric_set(rmse))

# collect rmse metrics

res_knn |> 
  collect_metrics()

# show best model

res_knn |> 
  show_best()

res_knn |> 
  autoplot()

# fit final knn model

final_wf_knn <-
  workflow_knn |> 
  finalize_workflow(select_best(res_knn))

final_fit_knn <-
  final_wf_knn |> 
  last_fit(modeling_sample)

final_fit_knn |> 
  collect_metrics
  
```

(Insert model here) has the lowest out of sample error rate

# Final model estimation on 2024 data
